= Developing XTDB2

The top-level project ties all the other projects together for convenience whilst working within this repo.
All of the below commands should be run in the *root* of the XT2 repo.

== Links

* https://github.com/orgs/xtdb/projects/13/views/1[Kanban board^]
* https://github.com/xtdb/xtdb/actions[Github Actions (CI)^]
* link:GIT.adoc[Git practices in XTDB]
* link:./doc[Developer documentation]

== Prerequisites

You will need at least JDK 21 installed.

== Getting started

XT2 uses https://gradle.org/[Gradle] - a JVM build tool that supports multi-module, polyglot projects.
You do not need to install Gradle to develop XT2 - there is a Gradle https://docs.gradle.org/current/userguide/gradle_wrapper.html[wrapper] in the repo.

* Java classes are (re-)compiled automatically when you (re-)start a REPL or run tests
* Start a REPL with `./gradlew :clojureRepl` (potentially requiring `./gradlew clean :clojureRepl`)
** `-PreplPort=7888` if you need the REPL on a specific port (e.g. for Clojure MCP)
* Once you've connected to the REPL, in the `user` namespace, run:
** `(dev)` to require and go to the `dev` namespace.
** `(go)` to start up the dev node
** `(halt)` to stop it
** `(reset)` to stop it, reload changed namespaces, and restart it
** if you're using Emacs/CIDER, `cider-ns-refresh` will do all this for you - `C-c M-n M-r`, `, s x` in Spacemacs, `, r r` in Doom.
** Conjure users can use `ConjureRefresh`, see the https://github.com/Olical/conjure#mappings[docs] for bindings
** see https://github.com/weavejester/integrant-repl[Integrant REPL] for more details.
* You should now have a running XTDB node under `dev/node` - you can verify this by calling `(xt/status node)` (in the `dev` namespace).
* Most of the time, you shouldn't need to bounce the REPL, but:
** if you add a module, or change any of the dependencies of any of the modules, that'll require a REPL bounce.
** if you change any of the Java classes, that'll require a REPL bounce
** otherwise, `(dev/reset)` (or just `(reset)` if you're already in the `dev` ns) should be sufficient.
** Please don't put any more side-effecting top-level code in dev namespaces - you'll break this reload ability and make me sad.
** To run a single test file, run (e.g.) `./gradlew test --tests 'xtdb.api_test**'`
** Run `git config core.hooksPath .githooks` to add xtdb hooks to your local repo.

== XTDB 'playground'

XTDB nodes can be started in 'playground' mode - either through `./gradlew :run`, `clj -m xtdb.main playground` or the standalone Docker image, or by running the `playground-config` `ir/set-prep` in the `dev` namespace.

In playground mode, to begin with, we only start the pgwire server, without an associated XTDB node.
Then, whenever a new connection is initiated, we create a new isolated in-memory node for every distinct 'database' specified in the connection parameters.

This is particularly useful for non-JVM testing - see the `/lang` README for more details.

== Attaching a debugger to the Clojure REPL

1. Add `-PdebugJvm` to the Gradle command - e.g. `./gradlew :clojureRepl -PdebugJvm` - you should see `Listening for transport dt_socket at address: 5005`.
.. Optionally, add `-PnoLocalsClearing` if Clojure's locals-clearing is getting in the way of you debugging (i.e. you're seeing a lot of null local variables in the debugger)
2. Connect the debugger - in IntelliJ, 'Run' -> 'Attach to Process' (or `Ctrl-Alt-5`).

== Testing

* Test all with `./gradlew test`; `./gradlew integration-test` for longer tests
* Property-based testing with `./gradlew property-test`
** Run with custom iterations: `./gradlew property-test -Piterations=500` (defaults to 100)
** Uses test.check generators to test with randomized data including composite types
* Some tests have external dependencies which require `docker-compose`:
** `docker-compose up` (`docker-compose up <kafka>` etc for individual containers),
** `./gradlew kafka-test`
** `docker-compose down`

=== Auth for testing cloud based resources

.*S3* (ensure all of the below are done on a consistent region):
* Need to ensure the `s3-stack` is setup via CloudFormation
** See the README for more info here.
* Need to log in to the AWS CLI - using `aws configure sso`
* Need to assume the role on the CLI - `aws sts assume-role --role-arn <ARN of XTDBIamRole> --role-session-name <session-name> --profile <SSO profile>`
* Set `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` & `AWS_SESSION_TOKEN` from the output
  of the above, then set AWS_REGION=<region for the cloudformation>
* Start the Gradle REPL and connect to it, to have all of the AWS creds available.

.*Azure*
* Ensure the Azure stack, `azure-resource-manager/azure-stack.json` stack is setup via the Azure deployment manager.
** See the README for more info here.
* Ensure a user/app registration is created with the create `xtdb-custom-role`.
* Create an access token for said user/app registration.
* Set `AZURE_CLIENT_ID` & `AZURE_CLIENT_SECRET` from the created access token.
* Set `AZURE_TENANT_ID` based on the tenant id on which you created the user/app registration/
* Set `AZURE_SUBSCRIPTION_ID` based on whichever subscription you created the stack on.
* Start the Gradle REPL and connect to it, to have all of the Azure creds available.

.*Google Cloud*
* Ensure the Google Cloud deployment, `cloud-deployment-manager/xtdb-object-store-stack.jinja`, is setup on the XTDB google cloud account.
** See the README for more info here.
* Ensure a https://console.cloud.google.com/iam-admin/serviceaccounts[Service Account] has been created for tests.
** Ensure the Service Account has the XTDB Custom Role created by the deployment above.
* Create a private key for the service account, saving a copy of the JSON credential file locally.
* Authenticate as the service account, using `gcloud auth activate-service-account <example-service-account@domain.com> --key-file <private-key.json>`
* Start the Gradle REPL and connect to it, to have all of the google cloud creds available.

== Profiling

To attach YourKit:

* Install YourKit (it's on the AUR, for Arch folks)
* `./gradlew :clojureRepl -Pyourkit`
* You might also want `-ParrowUnsafeMemoryAccess` which turns off bounds checking.
+
This assumes YourKit is installed under `/opt/yourkit` (as it does from the AUR) - feel free to adapt the property (or even use its value) if you have it installed elsewhere.

== Monitoring local dev

We can use our own local monitoring stack to see a number of metrics from the dev node - assuming you have a node with a healthz server available on port 8080, from the the base of the repo:

```
cd monitoring
docker-compose up -d
```

If you then go to http://localhost:3000/dashboards - you can log in (`admin/admin`) and see the prebuilt dashboards.

If you wish to make changes to these dashboards, see the guide in monitoring/README.adoc.

== Releasing XT2

See link:RELEASING.adoc[].

== Tooling

A couple of `./gradlew` tools:

Reading an Arrow file::
+
These tools output an Arrow file in EDN format
--
* `./gradlew -q :readArrowFile -Pfile=<file>`
* `./gradlew -q :readArrowStreamFile -Pfile=<file>` if it's in 'stream IPC' format.
* Pipe to a file: `./gradlew -q :readArrowFile -Pfile=<file> > output.edn`
--

Reading a hash trie file::
+
--
* `./gradlew -q :readHashTrieFile -Pfile=<file>`
* Pipe to a file: `./gradlew -q :readHashTrieFile -Pfile=<file> > output.edn`
--

Reading a table-block file::
+
--
* `./gradlew -q :readTableBlockFile -Pfile=<file>`
* Pipe to a file: `./gradlew -q :readTableBlockFile -Pfile=<file> > output.edn`
--

Reading crash logs::
+
--
Process crash logs into EDN format:

1. Run: `./dev/read-crash-log-folder.sh <crash-log-dir>`
2. EDN files will be output to `<crash-log-dir>/edn/`

Example: `./dev/read-crash-log-folder.sh /path/to/my-crash-logs` outputs to `/path/to/my-crash-logs/edn/`
--
