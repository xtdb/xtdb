-- gc.allium
--
-- Garbage collection of superseded tries.
-- Runs periodically, deleting data and meta files from the object store
-- once a trie has been fully replaced by compaction output.
--
-- Tries transition to garbage during addTries (see trie-cat.allium), not here.
-- This spec handles the physical cleanup: deleting files and removing catalog entries.
--
-- See: garbage_collector/GarbageCollector.kt, trie_catalog.clj (garbage-tries, garbage-fn)

use "./trie-cat.allium" as trie_cat

------------------------------------------------------------
-- Context
------------------------------------------------------------

-- No local entities; operates on trie_cat/trie_catalog and ObjectStore.

------------------------------------------------------------
-- External Entities
------------------------------------------------------------

external entity ObjectStore {
    -- Durable key-value storage for blocks, tries, table-blocks.
}

------------------------------------------------------------
-- Config
------------------------------------------------------------

config {
    blocks_to_keep: Integer = 10
    garbage_lifetime: Duration = 24.hours
}

------------------------------------------------------------
-- Rules
------------------------------------------------------------

-- A trie is eligible for deletion when:
--   1. Its state is garbage (set by addTries when a new trie supersedes it).
--   2. Its level is not 0 (see below).
--   3. Its garbage_as_of is <= the as_of threshold.
--
-- The as_of threshold provides a grace period:
--   as_of = system_time_of(block[latest - config.blocks_to_keep]) - config.garbage_lifetime
-- This ensures recently-superseded tries survive long enough for in-flight queries to finish.
--
-- L0 files are excluded from trie GC.
-- L0 forms a complete set of the data, so if anything goes wrong with deeper levels
-- we can reconstruct them entirely from the L0s. This has proved valuable on several
-- occasions during compactor development.
-- L0 files are small relative to compacted data (one per block, typically ~100K rows)
-- so the storage overhead of retaining them is negligible.
-- See: trie_catalog.clj (garbage-fn)

-- GC is scheduled externally on a periodic timer.
-- See: garbage_collector/GarbageCollector.kt (scheduleGc)

-- Returns the system_time of the block at `n` positions back from latest.
-- Returns null if fewer than `n` blocks exist.
-- See: buffer_pool/BufferPool.kt (blockFromLatest)
deferred latest_block_system_time(n: Int) -> Instant?

rule GarbageCollectorRuns {
    -- See: garbage_collector/GarbageCollector.kt
    when: GarbageCollectionScheduled()  -- external, periodic

    let block_time = latest_block_system_time(config.blocks_to_keep)

    -- If there aren't enough blocks yet, skip GC entirely.
    -- See: GarbageCollector.kt (defaultGarbageAsOf returning null, short-circuit via ?: return)
    requires: block_time != null

    let as_of = block_time - config.garbage_lifetime

    let eligible = trie_cat/trie_catalog.tries.values.flatten
        .filter(t => t.trie_state == garbage
                  and t.trie_key.level != 0
                  and t.garbage_as_of <= as_of)

    ensures:
        for each trie in eligible:
            -- Paths derived from trie.table and trie.trie_key; see trie/Trie.kt
            ObjectStore.delete(metaFilePath(trie.table, trie.trie_key))
            ObjectStore.delete(dataFilePath(trie.table, trie.trie_key))
        trie_cat/trie_catalog.deleteTries(eligible)
}
