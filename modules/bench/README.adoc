= Bench

== Running from Gradle

(from the root of the repo, values given are defaults)

TPC-H::
`./gradlew tpch -PscaleFactor=0.01`

AuctionMark::
`./gradlew auctionmark -Pduration=PT30S -Pthreads=8 -PscaleFactor=0.1`

Readings::
`./gradlew readings -PdeviceCount=10000 -PreadingCount=10000`

Products::
`./gradlew products`

IngestTsOverhead::
`./gradlew ingest -PdocCount=100000 -PbatchSizes=10,100,1000`


TSBS IoT::
`XTDB_LOGGING_LEVEL_BENCH_TSBS=debug ./gradlew :tsbs-iot -Pfile=/path/to/txs.transit.json`
+
For any reasonable scale you'll want to create a txs file beforehand - they take quite a while to generate in XT format.
See datasets -> `xtdb.tsbs`.

Add a YourKit snapshot with `-Pyourkit` - you should see a snapshot appear in your snapshot directory (default `~/Snapshots`) when the application shuts down.


In case you want to save the JSON benchmark log records to file you can append `-PbenchLogFile=tpch-0.01.log` to the command.

=== Running with custom config

You can run the benchmarks with a custom node config by passing `-PconfigFile path/to/config.yaml` to the gradle command.

`./gradlew auctionmark -PconfigFile=custom-config.yaml -Pduration=PT30S -Pthreads=8 -PscaleFactor=0.1`

== XTDB Bench Docker Image

The xtdb-bench Docker image is automatically built and pushed to GitHub Container Registry (GHCR) against the main branch every night. (tagged with `nightly`)


You can also manually build and push the image from any branch using the workflow_dispatch trigger in the "Build xtdb-bench Docker Image" GitHub Actions workflow (tagged with the Git SHA).

=== Running the Docker Image

From the root of the repository, you can run a benchmark with:

[source,bash]
----
docker run --rm ghcr.io/xtdb/xtdb-bench:nightly <benchmark-type> <opts...>
----

Replace <benchmark-type> with the name of the benchmark, and <opts...> with any additional CLI arguments (e.g., --node-dir, --config-file, etc.).

TPC-H::
[source,bash]
----
docker run --rm ghcr.io/xtdb/xtdb-bench:nightly tpch \
  --scale-factor 0.01
----
AuctionMark::
[source,bash]
----
docker run --rm ghcr.io/xtdb/xtdb-bench:nightly auctionmark \
  --duration PT30S \
  --scale-factor 0.1 \
  --threads 8
----
Readings::
[source,bash]
----
docker run --rm ghcr.io/xtdb/xtdb-bench:nightly readings \
  --devices 10000
  --readings 10000
----
Products::
[source,bash]
----
# ensure you've either downloaded the products dataset
# from S3 to datasets/products.transit.msgpack.gz,
# or your process has permissions to do so

docker run --rm ghcr.io/xtdb/xtdb-bench:nightly products
----

==== Running with custom config

You can run the benchmarks with a custom node config by passing `--config-file path/to/config.yaml` to the docker command.

[source,bash]
----
docker run --rm ghcr.io/xtdb/xtdb-bench:nightly auctionmark \
  --config-file custom-config.yaml \
  --duration PT30S \
  --threads 8 \
  --scale-factor 0.1
----

Included within the xtdb-bench are a number of config files for different cloud providers - see those under `cloud/config/`.

== Prometheus and Grafana

For local node monitoring, bring up a Prometheus and Grafana instance via `docker-compose up`.
By default the node serves Prometheus metrics under `localhost:8080/metrics` which Prometheus scrapes every 2 seconds.
If the metrics are not exposed under `localhost:8080` you need to tweak the `.config/prometheus.yaml` config accordingly.

Under `localhost:3001` you are able to access the Grafana UI (`admin` for user and password).
The XTDB node datasource should be setup, and there should be a dashboard available with some basic metrics.
If you tweak the dashboard or add a new one, save the changes in the corresponding file in `.config/dashboards/dashboard_name.json`.
