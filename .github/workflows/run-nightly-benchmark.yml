name: Run Nightly Benchmark

on:
  workflow_call:
    inputs:
      bench_type:
        description: 'Benchmark type passed to Helm'
        required: true
        type: string
      scale_factor:
        description: 'Scale factor applied to the benchmark chart values'
        required: false
        default: '1.0'
        type: string
      job_display_name:
        description: 'Label to show in the job name and Slack notifications'
        required: true
        type: string
      timeout_minutes:
        description: 'Job timeout in minutes'
        required: false
        default: 90
        type: number
      branch:
        description: 'Branch to build the benchmark image from'
        required: false
        default: 'main'
        type: string
      image_owner:
        description: 'Docker registry owner/organization for the benchmark image (defaults to repository owner)'
        required: false
        default: ''
        type: string
      duration:
        description: 'Duration for benchmarks that support it (e.g. PT30M for AuctionMark)'
        required: false
        default: ''
        type: string
      threads:
        description: 'Thread count for benchmarks that support it'
        required: false
        default: ''
        type: string
      node_count:
        description: 'Node count for benchmarks that support it'
        required: false
        default: ''
        type: string
      readings_device_count:
        description: 'Device count for readings benchmark'
        required: false
        default: ''
        type: string
      reading_count:
        description: 'Reading count for readings benchmark'
        required: false
        default: ''
        type: string

permissions:
  id-token: write
  contents: read
  actions: write
  packages: write

jobs:
  build-benchmark-image:
    uses: ./.github/workflows/bench-docker.yml
    with:
      branch: ${{ inputs.branch }}
      image_owner: ${{ inputs.image_owner }}

  benchmark:
    needs: build-benchmark-image
    name: "${{ inputs.job_display_name }} (SF: ${{ inputs.scale_factor }})"
    runs-on: ubuntu-latest
    timeout-minutes: ${{ inputs.timeout_minutes }}
    env:
      BENCH_TYPE: ${{ inputs.bench_type }}
      SCALE_FACTOR: ${{ inputs.scale_factor }}
      SLACK_LABEL: ${{ inputs.job_display_name }}
      GRAFANA_ADMIN_PASSWORD: ${{ secrets.BENCHMARK_GRAFANA_ADMIN_PASSWORD }}

    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5

      - name: Azure CLI Login
        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2
        with:
          client-id: ${{ secrets.BENCHMARK_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.BENCHMARK_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.BENCHMARK_AZURE_SUBSCRIPTION_ID }}

      - name: Acquire Kubernetes Configuration
        run: |
          az aks get-credentials --resource-group cloud-benchmark-resources --name xtdb-bench-cluster

      - name: Check Existing Deployment
        id: check-deployment
        continue-on-error: true
        run: |
          # exit 0 if exists, non-zero if not
          helm status xtdb-benchmark -n cloud-benchmark >/dev/null 2>&1

      - name: Inspect Existing Deployment
        if: steps.check-deployment.outcome == 'success'
        id: inspect-deployment
        run: |
          set -euo pipefail

          jobs_json=$(kubectl get jobs -n cloud-benchmark -o json 2>/dev/null || echo '{"items":[]}')
          job_count=$(echo "$jobs_json" | jq '.items | length')

          running_jobs_json=$(echo "$jobs_json" | jq -c '[.items[] | select((.status.active // 0) > 0) | .metadata.name]')
          failed_jobs_json=$(echo "$jobs_json" | jq -c '[.items[] | select((.status.failed // 0) > 0 or ((.status.conditions // []) | map(select(.type == "Failed" and .status == "True")) | length) > 0) | .metadata.name]')
          succeeded_jobs_json=$(echo "$jobs_json" | jq -c '[.items[] | select((.status.active // 0) == 0 and ((.status.succeeded // 0) > 0 or ((.status.conditions // []) | map(select(.type == "Complete" and .status == "True")) | length) > 0)) | .metadata.name]')
          terminal_jobs_json=$(echo "$jobs_json" | jq -c '[.items[] | select((.status.active // 0) == 0 and (((.status.succeeded // 0) > 0) or ((.status.failed // 0) > 0) or ((.status.conditions // []) | map(select((.type == "Complete" and .status == "True") or (.type == "Failed" and .status == "True"))) | length) > 0)) | .metadata.name]')
          pending_jobs_json=$(echo "$jobs_json" | jq -c '[.items[] | select((.status.active // 0) == 0 and ((.status.succeeded // 0) == 0) and ((.status.failed // 0) == 0) and ((.status.conditions // []) | length) == 0) | .metadata.name]')

          running_count=$(echo "$running_jobs_json" | jq 'length')
          failed_count=$(echo "$failed_jobs_json" | jq 'length')
          success_count=$(echo "$succeeded_jobs_json" | jq 'length')
          terminal_count=$(echo "$terminal_jobs_json" | jq 'length')
          pending_count=$(echo "$pending_jobs_json" | jq 'length')



          if [ "$job_count" -eq 0 ]; then
            DEPLOYMENT_STATUS="completed"
          elif [ "$running_count" -gt 0 ]; then
            DEPLOYMENT_STATUS="in_progress"
          elif [ "$failed_count" -gt 0 ]; then
            DEPLOYMENT_STATUS="failed"
          elif [ "$success_count" -gt 0 ] || [ "$terminal_count" -gt 0 ]; then
            DEPLOYMENT_STATUS="completed"
          elif [ "$pending_count" -gt 0 ]; then
            DEPLOYMENT_STATUS="in_progress"
          else
            DEPLOYMENT_STATUS="in_progress"
          fi

          echo "Existing deployment status: ${DEPLOYMENT_STATUS}"
          echo "Jobs discovered: $(echo "$jobs_json" | jq -r '[.items[].metadata.name] | join(", ")')"
          echo "Running jobs: $(echo "$running_jobs_json" | jq -r 'join(", ")')"
          echo "Failed jobs: $(echo "$failed_jobs_json" | jq -r 'join(", ")')"
          echo "Succeeded jobs: $(echo "$succeeded_jobs_json" | jq -r 'join(", ")')"
          echo "Terminal jobs: $(echo "$terminal_jobs_json" | jq -r 'join(", ")')"

          echo "deployment_status=${DEPLOYMENT_STATUS}" >> "$GITHUB_OUTPUT"
          echo "job_names=$(echo "$jobs_json" | jq -c '[.items[].metadata.name]')" >> "$GITHUB_OUTPUT"
          echo "terminal_job_names=${terminal_jobs_json}" >> "$GITHUB_OUTPUT"
          echo "failed_job_names=${failed_jobs_json}" >> "$GITHUB_OUTPUT"
          echo "succeeded_job_names=${succeeded_jobs_json}" >> "$GITHUB_OUTPUT"

      - name: Cleanup Existing Deployment
        if: steps.inspect-deployment.outputs.deployment_status == 'completed' || steps.inspect-deployment.outputs.deployment_status == 'failed'
        run: |
          set -euo pipefail
          echo "Previous benchmark finished with status: ${{ steps.inspect-deployment.outputs.deployment_status }}. Cleaning up release before proceeding."
          ./modules/bench/cloud/clear-bench.sh azure

      - name: Cancel workflow (existing deployment)
        if: steps.check-deployment.outcome == 'success' && steps.inspect-deployment.outputs.deployment_status == 'in_progress'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            core.notice('Existing deployment found and still in progress. Cancelling this workflow run to avoid overlap.');
            await github.rest.actions.cancelWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
            });

      - name: Stop job after cancellation
        if: steps.check-deployment.outcome == 'success' && steps.inspect-deployment.outputs.deployment_status == 'in_progress'
        run: |
          echo "Workflow cancellation requested due to existing deployment. Stopping job."
          exit 0

      - name: Clear Bench State
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        continue-on-error: true
        run: |
          echo "Ensuring clean state before starting benchmark..."
          ./modules/bench/cloud/clear-bench.sh azure || true

      - name: Install Monitoring Stack
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        continue-on-error: true
        run: |
          bash ./modules/bench/cloud/monitoring/install-monitoring.sh

      - name: Create Bench Secret (GITHUB_PAT)
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        run: |
          set -euo pipefail
          kubectl -n cloud-benchmark create secret generic xtdb-bench-secrets \
            --from-literal=GITHUB_PAT="${{ secrets.BENCHMARK_GITHUB_PAT }}" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Record Deployment Start
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        run: echo "DEPLOY_START=$(date -u +%s)" >> "$GITHUB_ENV"

      - name: Run Benchmark
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        env:
          BENCH_TYPE: ${{ env.BENCH_TYPE }}
          SCALE_FACTOR: ${{ env.SCALE_FACTOR }}
          IMAGE_TAG: ${{ needs.build-benchmark-image.outputs.image_tag }}
          IMAGE_OWNER: ${{ inputs.image_owner || github.repository_owner }}
          GIT_SHA: ${{ github.sha }}
          GIT_BRANCH: ${{ inputs.branch }}
          GIT_REPO: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          DURATION: ${{ inputs.duration }}
          THREADS: ${{ inputs.threads }}
          NODE_COUNT: ${{ inputs.node_count }}
          READINGS_DEVICE_COUNT: ${{ inputs.readings_device_count }}
          READING_COUNT: ${{ inputs.reading_count }}
        run: |
          helm dependency update ./modules/bench/cloud/helm
          HELM_ARGS=(
            --namespace "cloud-benchmark"
            --create-namespace
            -f ./modules/bench/cloud/azure/values.yaml
            --set "benchType=${BENCH_TYPE}"
            --set "image.repository=ghcr.io/${IMAGE_OWNER}/xtdb-bench"
            --set "image.tag=${IMAGE_TAG}"
            --set "git.sha=${GIT_SHA}"
            --set "git.branch=${GIT_BRANCH}"
            --set "git.repo=${GIT_REPO}"
            --set "git.runId=${GITHUB_RUN_ID}"
            --set "providerConfig.existingSecret=xtdb-bench-secrets"
            --set "providerConfig.env.AZURE_USER_MANAGED_IDENTITY_CLIENT_ID=${{ secrets.BENCHMARK_AZURE_USER_MANAGED_IDENTITY_CLIENT_ID }}"
            --set "providerConfig.serviceAccountAnnotations.azure\.workload\.identity/client-id=${{ secrets.BENCHMARK_AZURE_USER_MANAGED_IDENTITY_CLIENT_ID }}"
          )

          # Add optional parameters if provided
          if [ -n "$SCALE_FACTOR" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.scaleFactor=${SCALE_FACTOR}")
          fi
          if [ -n "$DURATION" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.duration=${DURATION}")
          fi
          if [ -n "$THREADS" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.threads=${THREADS}")
          fi
          if [ -n "$NODE_COUNT" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.nodeCount=${NODE_COUNT}")
          fi
          if [ -n "$READINGS_DEVICE_COUNT" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.devices=${READINGS_DEVICE_COUNT}")
          fi
          if [ -n "$READING_COUNT" ]; then
            HELM_ARGS+=(--set "${BENCH_TYPE}.readings=${READING_COUNT}")
          fi

          helm upgrade --install "xtdb-benchmark" ./modules/bench/cloud/helm "${HELM_ARGS[@]}"

      - name: Check for Immediate Benchmark Failure
        id: immediate-check
        if: steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress'
        env:
          SLACK_LABEL: ${{ env.SLACK_LABEL }}
        run: |
          set -euo pipefail

          echo "immediate_failure=false" >> "$GITHUB_OUTPUT"
          ATTEMPTS=36
          SLEEP_SECONDS=10
          REQUIRED_RUNNING_SECONDS=120
          running_since=""
          echo "Checking for immediate benchmark pod failures..."
          for attempt in $(seq 1 "$ATTEMPTS"); do
            pods_json=$(kubectl get pods -n cloud-benchmark -o json)

            pods=$(echo "$pods_json" | jq '[.items[]
              | select((.metadata.labels["app.kubernetes.io/component"] // "") == "benchmark")
            ]')
            pod_count=$(echo "$pods" | jq 'length')
            if [ "$pod_count" -eq 0 ]; then
              echo "Attempt ${attempt}/${ATTEMPTS}: no benchmark pods detected yet."
              sleep "$SLEEP_SECONDS"
              continue
            fi

            failing_pods=$(echo "$pods" | jq '
              [.[]
               | select(
                   (.status.phase == "Failed")
                   or ((.status.containerStatuses // [])
                       | any(
                           ((.state.terminated // null) != null and ((.state.terminated.exitCode // 0) != 0))
                           or ((.state.waiting // null) != null and ((.state.waiting.reason // "") | test("CrashLoopBackOff|ImagePullBackOff|ErrImagePull|CreateContainerConfigError|RunContainerError|ContainerCannotRun|Error")))
                         ))
                   or ((.status.initContainerStatuses // [])
                       | any(
                           ((.state.terminated // null) != null and ((.state.terminated.exitCode // 0) != 0))
                           or ((.state.waiting // null) != null and ((.state.waiting.reason // "") | test("CrashLoopBackOff|ImagePullBackOff|ErrImagePull|CreateContainerConfigError|RunContainerError|ContainerCannotRun|Error")))
                         ))
                 )
               | .metadata.name
              ]')
            failing_count=$(echo "$failing_pods" | jq 'length')

            if [ "$failing_count" -gt 0 ]; then
              echo "error detected: ${failing_count} failing benchmark pod(s) soon after deployment."
              echo "immediate_failure=true" >> "$GITHUB_OUTPUT"
              mapfile -t pod_names < <(echo "$failing_pods" | jq -r '.[]')
              primary_pod="${pod_names[0]:-}"
              if [ -n "$primary_pod" ]; then
                echo "immediate_failure_pod=${primary_pod}" >> "$GITHUB_OUTPUT"
                failure_log_path="$RUNNER_TEMP/immediate-failure-${primary_pod}.log"
                if kubectl logs "$primary_pod" -n cloud-benchmark --all-containers=true --tail=200 > "$failure_log_path" 2>/dev/null; then
                  head -n 60 "$failure_log_path" > "${failure_log_path}.preview"
                  mv "${failure_log_path}.preview" "$failure_log_path"
                  echo "immediate_failure_log_path=${failure_log_path}" >> "$GITHUB_OUTPUT"
                fi
              fi
              cleanup_triggered=false
              for pod in "${pod_names[@]}"; do
                echo "describe ${pod}"
                kubectl describe pod "${pod}" -n cloud-benchmark || true

                echo "logs ${pod}"
                pod_log="$(kubectl logs "${pod}" -n cloud-benchmark --all-containers=true 2>/dev/null || true)"
                echo "$pod_log"

                if printf '%s' "$pod_log" | grep -q "Triggered cleanup workflow"; then
                  cleanup_triggered=true
                fi
              done

              if [ "$cleanup_triggered" != true ]; then
                echo "No cleanup workflow trigger detected in logs; invoking clear-bench script." >&2
                ./modules/bench/cloud/clear-bench.sh azure || true
              fi
              exit 1
            fi

            completed_count=$(echo "$pods" | jq '[.[] | select(.status.phase == "Succeeded")] | length')
            if [ "$completed_count" -gt 0 ]; then
              echo "Benchmark job already completed successfully."
              exit 0
            fi

            running_count=$(echo "$pods" | jq '[.[]
              | select(
                  (.status.phase == "Running")
                  and ((.status.containerStatuses // [])
                       | any((.state.running // null) != null))
                  and ((.status.initContainerStatuses // [])
                       | all(
                           ((.state.terminated // null) != null)
                           and ((.state.terminated.exitCode // 0) == 0)
                         ))
                )
            ] | length')

            if [ "$running_count" -gt 0 ]; then
              if [ -z "$running_since" ]; then
                running_since=$(date -u +%s)
                echo "Benchmark pods entered running state; starting stability timer."
              else
                now_ts=$(date -u +%s)
                elapsed=$((now_ts - running_since))
                echo "Benchmark pods running for ${elapsed}s (target: ${REQUIRED_RUNNING_SECONDS}s)."
                if [ "$elapsed" -ge "$REQUIRED_RUNNING_SECONDS" ]; then
                  echo "Benchmark pods have been running for at least ${REQUIRED_RUNNING_SECONDS}s; considering startup successful."
                  exit 0
                fi
              fi
            else
              if [ -n "$running_since" ]; then
                echo "Benchmark pods no longer running; resetting stability timer."
              fi
              running_since=""
            fi

            sleep "$SLEEP_SECONDS"
          done

          echo "No immediate benchmark pod failures detected in the initial monitoring window."

      - name: Remove Monitoring Stack on Failure
        if: failure() && (steps.check-deployment.outcome != 'success' || steps.inspect-deployment.outputs.deployment_status != 'in_progress')
        run: |
          if helm status monitoring -n monitoring >/dev/null 2>&1; then
            echo "Uninstalling monitoring stack due to benchmark failure..."
            helm uninstall monitoring -n monitoring || true
            # Attempt to delete the namespace (ignore if it contains other resources or is already gone)
            kubectl delete namespace monitoring --ignore-not-found=true || true
          else
            echo "Monitoring stack not found; skipping."
          fi

      - name: Compose Slack Message
        id: compose
        if: always()
        env:
          SLACK_LABEL: ${{ env.SLACK_LABEL }}
          SCALE_FACTOR: ${{ env.SCALE_FACTOR }}
          DURATION: ${{ inputs.duration }}
          THREADS: ${{ inputs.threads }}
          NODE_COUNT: ${{ inputs.node_count }}
          READINGS_DEVICE_COUNT: ${{ inputs.readings_device_count }}
          READING_COUNT: ${{ inputs.reading_count }}
          GIT_SHA: ${{ github.sha }}
          GIT_BRANCH: ${{ inputs.branch }}
          REPO_URL: ${{ github.server_url }}/${{ github.repository }}
          IMAGE_OWNER: ${{ inputs.image_owner || github.repository_owner }}
          IMAGE_TAG: ${{ needs.build-benchmark-image.outputs.image_tag }}
        run: |
          set -euo pipefail

          SHORT_SHA="${GIT_SHA:0:7}"
          GIT_INFO="Branch: <${REPO_URL}/tree/${GIT_BRANCH}|\`${GIT_BRANCH}\`> | Commit: <${REPO_URL}/commit/${GIT_SHA}|\`${SHORT_SHA}\`>"
          IMAGE="ghcr.io/${IMAGE_OWNER}/xtdb-bench:${IMAGE_TAG}"
          # Strip ghcr.io/ prefix for display
          IMAGE_DISPLAY="${IMAGE#ghcr.io/}"
          IMAGE_INFO="Image: <https://github.com/${IMAGE_OWNER}/xtdb-bench/pkgs/container/xtdb-bench|\`${IMAGE_DISPLAY}\`>"

          # Build config info
          CONFIG_PARTS=()
          [ -n "$SCALE_FACTOR" ] && CONFIG_PARTS+=("Scale Factor: ${SCALE_FACTOR}")
          [ -n "$DURATION" ] && CONFIG_PARTS+=("Duration: ${DURATION}")
          [ -n "$THREADS" ] && CONFIG_PARTS+=("Threads: ${THREADS}")
          [ -n "$NODE_COUNT" ] && CONFIG_PARTS+=("Nodes: ${NODE_COUNT}")
          [ -n "$READINGS_DEVICE_COUNT" ] && CONFIG_PARTS+=("Devices: ${READINGS_DEVICE_COUNT}")
          [ -n "$READING_COUNT" ] && CONFIG_PARTS+=("Readings: ${READING_COUNT}")
          # Join with " | "
          CONFIG_INFO=$(printf " | %s" "${CONFIG_PARTS[@]}")
          CONFIG_INFO="${CONFIG_INFO:3}" # Strip leading " | "

          if [ "${{ steps.check-deployment.outcome }}" = "success" ] && [ "${{ steps.inspect-deployment.outputs.deployment_status }}" = "in_progress" ]; then
            {
              echo 'msg<<EOF_MSG'
              echo "*${SLACK_LABEL} Benchmark* :information_source: Skipped â€” existing deployment found"
              echo "${GIT_INFO}"
              echo "${IMAGE_INFO}"
              echo 'EOF_MSG'
            } >> "$GITHUB_OUTPUT"
          elif [ "${{ steps.immediate-check.outputs.immediate_failure }}" = "true" ]; then
            POD_NAME='${{ steps.immediate-check.outputs.immediate_failure_pod }}'
            LOG_PATH='${{ steps.immediate-check.outputs.immediate_failure_log_path }}'
            MSG_FILE="$RUNNER_TEMP/slack-immediate-failure.txt"
            : > "$MSG_FILE"
            {
              printf '*%s Benchmark* :x: Failed during startup (pod: `%s`)\n' "${SLACK_LABEL}" "${POD_NAME:-unknown}"
              echo "${GIT_INFO}"
              echo "${IMAGE_INFO}"
              if [ -n "$LOG_PATH" ] && [ -f "$LOG_PATH" ]; then
                echo >> "$MSG_FILE"
                echo '```' >> "$MSG_FILE"
                cat "$LOG_PATH" >> "$MSG_FILE"
                echo '```' >> "$MSG_FILE"
              fi
            } >> "$MSG_FILE"

            {
              echo 'msg<<EOF_MSG'
              cat "$MSG_FILE"
              echo 'EOF_MSG'
            } >> "$GITHUB_OUTPUT"
          else
            {
              echo 'msg<<EOF_MSG'
              echo "*${SLACK_LABEL} Benchmark* :rocket: Started (${CONFIG_INFO})"
              echo "${GIT_INFO}"
              echo "${IMAGE_INFO}"
              echo 'EOF_MSG'
            } >> "$GITHUB_OUTPUT"
          fi

      - name: Prepare Slack Message
        if: always()
        run: |
          jq -n --arg channel "$SLACK_CHANNEL" --arg text "$SLACK_MESSAGE" \
            '{channel: $channel, text: $text}' > slack-message.json
        env:
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
          SLACK_MESSAGE: ${{ steps.compose.outputs.msg }}

      - name: Post Slack Notification
        if: always()
        uses: slackapi/slack-github-action@485a9d42d3a73031f12ec201c457e2162c45d02d # v2.0.0
        with:
          method: chat.postMessage
          token: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          payload-file-path: ./slack-message.json
