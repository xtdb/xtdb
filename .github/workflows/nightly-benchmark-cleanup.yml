name: Nightly Benchmark Cleanup
run-name: >-
  Benchmark Cleanup: ${{ inputs.benchType == 'tpch' && 'TPC-H' || inputs.benchType == 'auctionmark' && 'AuctionMark' || inputs.benchType == 'readings' && 'Readings' || inputs.benchType == 'yakbench' && 'Yakbench' || inputs.benchType }}

on:
  workflow_dispatch:
    inputs:
      benchType:
        description: 'Type of benchmark to clean up'
        required: true
        type: choice
        options:
          - tpch
          - auctionmark
          - readings
          - yakbench
      status:
        description: 'Status of the benchmark'
        required: true
        type: choice
        options:
          - success
          - failure
      nodeId:
        description: 'Node ID of the benchmark'
        required: true
        type: string

permissions:
  id-token: write
  contents: read
  actions: write

concurrency:
  group: cleanup-benchmarks
  cancel-in-progress: false

jobs:
  cleanup:
    runs-on: ubuntu-latest
    env:
      GRAFANA_ADMIN_PASSWORD: ${{ secrets.BENCHMARK_GRAFANA_ADMIN_PASSWORD }}
    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5

      - name: Install Babashka
        run: |
          set -euo pipefail
          BABASHKA_VERSION=1.12.209
          curl -sSfL "https://github.com/babashka/babashka/releases/download/v${BABASHKA_VERSION}/babashka-${BABASHKA_VERSION}-linux-amd64.tar.gz" -o /tmp/babashka.tar.gz
          sudo tar -xzf /tmp/babashka.tar.gz -C /usr/local/bin bb
          rm -f /tmp/babashka.tar.gz
          bb --version

      - name: Azure CLI Login
        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2
        with:
          client-id: ${{ secrets.BENCHMARK_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.BENCHMARK_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.BENCHMARK_AZURE_SUBSCRIPTION_ID }}

      - name: Acquire Kubernetes Configuration
        run: |
          az aks get-credentials --resource-group cloud-benchmark-resources --name xtdb-bench-cluster

      - name: Check Deployment
        id: check-deployment
        continue-on-error: true
        run: |
          # exit 0 if exists, non-zero if not
          helm status xtdb-benchmark -n cloud-benchmark >/dev/null 2>&1

      - name: Cancel workflow (no deployment found)
        if: steps.check-deployment.outcome != 'success'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            core.notice('No benchmark deployment found. Cancelling cleanup workflow run.');
            await github.rest.actions.cancelWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
            });

      - name: Stop job after cancellation
        if: steps.check-deployment.outcome != 'success'
        run: |
          echo "Cleanup workflow cancellation requested due to missing deployment. Stopping job."
          exit 0

      - name: Wait for Benchmark Job and Pods to Complete
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          JOB="${{ inputs.benchType }}"
          NS="cloud-benchmark"

          # Check current pod states for informational purposes
          sel='-l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark'
          failed_cnt=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase=Failed --no-headers 2>/dev/null | wc -l | tr -d ' ')
          succeeded_cnt=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase=Succeeded --no-headers 2>/dev/null | wc -l | tr -d ' ')
          nonterminal_cnt=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase!=Succeeded,status.phase!=Failed --no-headers 2>/dev/null | wc -l | tr -d ' ')

          echo "Current pod state: ${succeeded_cnt:-0} succeeded, ${failed_cnt:-0} failed, ${nonterminal_cnt:-0} non-terminal"

          # Always wait for the benchmark Job to reach a terminal state
          # This ensures we don't prematurely cleanup while the job is still running
          if kubectl get job "$JOB" -n "$NS" >/dev/null 2>&1; then
            echo "Polling job/$JOB until Complete or Failed..."
            # Poll up to ~2h (720 * 10s)
            for i in $(seq 1 720); do
              COMPLETE=$(kubectl get job "$JOB" -n "$NS" -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' || true)
              FAILED=$(kubectl get job "$JOB" -n "$NS" -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' || true)
              if [ "$COMPLETE" = "True" ]; then
                echo "job/$JOB Complete"
                break
              fi
              if [ "$FAILED" = "True" ]; then
                echo "job/$JOB Failed"
                break
              fi

              # Optional: stop early if all benchmark pods are terminal
              remaining=$(kubectl get pods -n "$NS" \
                -l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark \
                --field-selector=status.phase!=Succeeded,status.phase!=Failed \
                --no-headers 2>/dev/null | wc -l | tr -d ' ')
              if [ "${remaining:-0}" = "0" ]; then
                echo "All benchmark pods are terminal; stopping job wait"
                break
              fi

              sleep 10
            done
          else
            echo "job/$JOB not found in namespace $NS; continuing"
          fi

          # Gracefully wait for benchmark pods to finish terminating
          # (pods created by the benchmark Job under app.kubernetes.io/name=xtdb & component=benchmark)
          for i in $(seq 1 30); do
            remaining=$(kubectl get pods -n "$NS" \
              -l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark \
              --field-selector=status.phase!=Succeeded,status.phase!=Failed \
              --no-headers 2>/dev/null | wc -l | tr -d ' ')
            if [ "${remaining:-0}" = "0" ]; then
              echo "All benchmark pods completed/terminated"
              break
            fi
            echo "Waiting for benchmark pods to complete... ($i) remaining=$remaining"
            sleep 4
          done

          # Final verification that all pods are in terminal state
          final_nonterminal=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase!=Succeeded,status.phase!=Failed --no-headers 2>/dev/null | wc -l | tr -d ' ')
          if [ "${final_nonterminal:-0}" != "0" ]; then
            echo "WARNING: ${final_nonterminal} pods are still not in terminal state after waiting"
            kubectl get pods -n "$NS" $sel --no-headers
          else
            echo "Verified: All benchmark pods are in terminal state"
          fi

      - name: Determine Benchmark Status
        id: derive
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          JOB="${{ inputs.benchType }}"
          NS="cloud-benchmark"

          STATUS="unknown"
          if kubectl get job "$JOB" -n "$NS" >/dev/null 2>&1; then
            COMPLETE=$(kubectl get job "$JOB" -n "$NS" -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' || true)
            FAILED=$(kubectl get job "$JOB" -n "$NS" -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' || true)
            if [ "$FAILED" = "True" ]; then STATUS="failure"; fi
            if [ "$COMPLETE" = "True" ]; then STATUS="success"; fi
          else
            # If the job isn't present, infer from pods: any Failed pod => failure, any Succeeded pod => success
            sel='-l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark'
            failed_cnt=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase=Failed --no-headers 2>/dev/null | wc -l | tr -d ' ')
            succeeded_cnt=$(kubectl get pods -n "$NS" $sel --field-selector=status.phase=Succeeded --no-headers 2>/dev/null | wc -l | tr -d ' ')
            if [ "${failed_cnt:-0}" -gt 0 ]; then STATUS="failure";
            elif [ "${succeeded_cnt:-0}" -gt 0 ]; then STATUS="success";
            fi
          fi

          echo "bench_status=${STATUS}" >> "$GITHUB_OUTPUT"
          echo "Derived benchmark status: ${STATUS}"

      - name: Capture Benchmark Logs (All Pods)
        if: steps.check-deployment.outcome == 'success'
        id: logs
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          JOB_NAME="${{ inputs.benchType }}"

          mkdir -p pod-logs
          pods=$(kubectl get pods -n "$NS" -l job-name="$JOB_NAME" -o jsonpath='{.items[*].metadata.name}' || true)

          # Fallback selector (in case job-name label is missing): select XTDB benchmark pods by component/name
          if [ -z "$pods" ]; then
            pods=$(kubectl get pods -n "$NS" -l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark -o jsonpath='{.items[*].metadata.name}' || true)
          fi

          # Download logs for each pod with a small retry loop
          total_ms=0
          count_ms=0
          primary_log=""
          for pod in $pods; do
            attempts=0
            # Try primary container logs explicitly, with retries (handles pods that are still terminating)
            until kubectl logs "$pod" -n "$NS" -c xtdb-node > "pod-logs/$pod.log" 2>/dev/null || \
                  kubectl logs "$pod" -n "$NS" > "pod-logs/$pod.log" 2>/dev/null || \
                  [ $attempts -ge 12 ]; do
              attempts=$((attempts+1))
              echo "Waiting for logs from $pod (attempt $attempts)..."
              sleep 5
            done

            # If empty or unavailable, try previous logs (in case of restarts)
            if [ ! -s "pod-logs/$pod.log" ]; then
              kubectl logs "$pod" -n "$NS" -c xtdb-node --previous > "pod-logs/$pod.previous.log" 2>/dev/null || \
              kubectl logs "$pod" -n "$NS" --previous > "pod-logs/$pod.previous.log" 2>/dev/null || true
            fi

            # If still nothing, capture describe for diagnostics
            if [ ! -s "pod-logs/$pod.log" ] && [ ! -s "pod-logs/$pod.previous.log" ]; then
              kubectl describe pod "$pod" -n "$NS" > "pod-logs/$pod.describe.txt" 2>/dev/null || true
            fi
            # Choose a primary log for convenience (use previous if primary absent)
            if [ -z "$primary_log" ]; then
              src_for_primary=""
              if [ -s "pod-logs/$pod.log" ]; then src_for_primary="pod-logs/$pod.log"; fi
              if [ -z "$src_for_primary" ] && [ -s "pod-logs/$pod.previous.log" ]; then src_for_primary="pod-logs/$pod.previous.log"; fi
              if [ -n "$src_for_primary" ]; then
                cp "$src_for_primary" benchmark.log || true
                primary_log="$pod"
              fi
            fi
            if [ -s "pod-logs/$pod.log" ] || [ -s "pod-logs/$pod.previous.log" ]; then
              # Extract last time-taken-ms in this pod's log
              src_log="pod-logs/$pod.log"
              [ -s "pod-logs/$pod.log" ] || src_log="pod-logs/$pod.previous.log"
              pod_ms=$(grep -o '"time-taken-ms":[0-9]\+' "$src_log" | tail -1 | cut -d: -f2 || true)
              if [ -n "$pod_ms" ]; then
                total_ms=$((total_ms + pod_ms))
                count_ms=$((count_ms + 1))
              fi
              # Capture params EDN once (supports tpch, auctionmark, or yakbench namespaces in loggers)
              if [ -z "${{ steps.logs.outputs.params_edn || '' }}" ]; then
                params_line=$(grep -m1 -E 'INFO[[:space:]]+xtdb\.bench\.(tpch|auctionmark|yakbench)[[:space:]]+-[[:space:]]+\{.*\}' "$src_log" || true)
                if [ -n "$params_line" ]; then
                  params_edn=$(echo "$params_line" | sed -E 's/.*INFO[[:space:]]+xtdb\.bench\.(tpch|auctionmark|yakbench)[[:space:]]+-[[:space:]]+(\{.*\}).*/\2/')
                  {
                    echo 'params_edn<<EOF'
                    echo "$params_edn"
                    echo 'EOF'
                  } >> "$GITHUB_OUTPUT"
                  sf=$(echo "$params_edn" | sed -nE 's/.*:scale-factor[[:space:]]+([0-9.]+).*/\1/p' || true)
                  if [ -n "${sf}" ]; then
                    echo "SCALE_FACTOR=${sf}" >> "$GITHUB_ENV"
                  fi
                fi
              fi
            fi
          done

          # If we never picked a primary, try the nodeId the job passed us
          if [ -z "$primary_log" ]; then
            if kubectl logs "${{ inputs.nodeId }}" -n "$NS" > benchmark.log 2>/dev/null; then
              primary_log="${{ inputs.nodeId }}"
            fi
          fi

          # Compute average time if we have any samples
          if [ "$count_ms" -gt 0 ]; then
            avg_ms=$((total_ms / count_ms))
            echo "time_taken=$avg_ms" >> "$GITHUB_OUTPUT"

            total_seconds=$((avg_ms / 1000))
            rem_ms=$((avg_ms % 1000))
            hours=$((total_seconds / 3600))
            minutes=$(((total_seconds % 3600) / 60))
            seconds=$((total_seconds % 60))
            sec_str="$seconds"
            if [ "$rem_ms" -gt 0 ]; then
              ms_padded=$(printf "%03d" "$rem_ms")
              sec_str="${seconds}.${ms_padded}"
            fi
            duration="PT"
            if [ "$hours" -gt 0 ]; then duration="${duration}${hours}H"; fi
            if [ "$minutes" -gt 0 ]; then duration="${duration}${minutes}M"; fi
            if [ "$seconds" -gt 0 ] || [ "$rem_ms" -gt 0 ] || [ "$duration" = "PT" ]; then
              duration="${duration}${sec_str}S"
            fi
            echo "time_taken_iso=$duration" >> "$GITHUB_OUTPUT"
          fi

      - name: Set Timestamp
        id: timestamp
        run: |
          echo "value=$(date -u +"%Y-%m-%d-%H-%M-%S")" >> "$GITHUB_OUTPUT"
          echo "date=$(date -u +"%Y/%m/%d")" >> "$GITHUB_OUTPUT"

      - name: Upload Benchmark Logs
        id: upload-logs
        if: steps.check-deployment.outcome == 'success' && hashFiles('benchmark.log', 'pod-logs/*.log') != ''
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: benchmark-logs-${{ inputs.benchType }}-${{ steps.timestamp.outputs.value }}-${{ inputs.nodeId }}-${{ steps.derive.outputs.bench_status || inputs.status }}
          path: |
            pod-logs/*.log
          retention-days: 7

      - name: Compute Grafana Time Range
        id: grafana-time
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          FROM_PARAM="now-2h"
          TO_PARAM="now"
          if [ -f benchmark.log ]; then
            # Extract first timestamp like HH:MM:SS.mmm
            start_ts=$(grep -m1 -oE '^[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{3}' benchmark.log || true)
            if [ -n "$start_ts" ]; then
              start_hms=${start_ts%.*}
              start_ms=${start_ts#*.}
              today=$(date -u +%Y-%m-%d)
              # Candidates: today and yesterday (to handle jobs crossing midnight UTC)
              cand1=$(date -u -d "$today $start_hms" +%s 2>/dev/null || echo "")
              yesterday=$(date -u -d "$today - 1 day" +%Y-%m-%d)
              cand2=$(date -u -d "$yesterday $start_hms" +%s 2>/dev/null || echo "")
              now_s=$(date -u +%s)
              pick=""
              if [ -n "$cand1" ] && [ "$cand1" -le "$now_s" ]; then pick="$cand1"; fi
              if [ -n "$cand2" ] && [ "$cand2" -le "$now_s" ]; then
                if [ -z "$pick" ] || [ $((now_s - cand2)) -lt $((now_s - pick)) ]; then pick="$cand2"; fi
              fi
              if [ -n "$pick" ]; then
                # Ensure ms parsed as decimal even with leading zeros
                FROM_PARAM=$((pick * 1000 + 10#${start_ms}))
                TO_PARAM="$(date -u +%s000)"
              fi
            fi
          fi
          echo "from=$FROM_PARAM" >> "$GITHUB_OUTPUT"
          echo "to=$TO_PARAM" >> "$GITHUB_OUTPUT"

      - name: Port-forward Grafana (background)
        if: steps.check-deployment.outcome == 'success'
        run: |
          # Start port-forward in background
          kubectl -n monitoring port-forward svc/monitoring-grafana 3000:80 >/tmp/grafana-pf.log 2>&1 &
          echo $! > /tmp/grafana-pf.pid
          # Wait for Grafana to be reachable
          for i in {1..30}; do
            if curl -sSf http://localhost:3000/api/health > /dev/null; then
              echo "Grafana is reachable"
              break
            fi
            echo "Waiting for Grafana port-forward... ($i)"
            sleep 2
          done

      - name: Render Cluster Monitoring Panels
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          mkdir -p grafana-panels
          DASHBOARD_UID="aeews5bgs0zk0b"
          FROM="${{ steps.grafana-time.outputs.from || 'now-2h' }}"
          TO="${{ steps.grafana-time.outputs.to || 'now' }}"
          WIDTH=1600
          HEIGHT=900
          SLUG="xtdb-monitoring-dashboard"

          # Declare panels: [title]=panelId
          declare -A PANELS=(
            ["# Nodes"]=1
            ["Transaction Lag"]=3
            ["Max Transaction Latency (Over Time)"]=5
            ["Max Query Latency (Over Time)"]=6
            ["Cluster Transactions"]=8
            ["Cluster Transactions Latencies"]=7
            ["Cluster Transaction Errors"]=22
            ["Cluster Queries"]=9
            ["Cluster Query Latencies"]=10
            ["Cluster Query Errors"]=20
            ["Cluster PGWire Active Connections"]=23
          )

          # Simple slugify for file names
          slugify() {
            echo "$1" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g; s/^-+|-+$//g'
          }

          for title in "${!PANELS[@]}"; do
            panelId="${PANELS[$title]}"
            file="grafana-panels/$(slugify "$title").png"
            url="http://localhost:3000/render/d-solo/${DASHBOARD_UID}/${SLUG}?panelId=${panelId}&orgId=1&from=${FROM}&to=${TO}&width=${WIDTH}&height=${HEIGHT}&tz=UTC"
            echo "Rendering [$title] (panelId=${panelId}) -> $file"
            curl -sS -f -L -u "admin:${GRAFANA_ADMIN_PASSWORD}" -H 'Accept: image/png' "$url" -o "$file" || echo "Failed to render $title"
          done

      - name: Render Node Debugging Panels
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          # Determine all XTDB node ids (pod names) to use for var-xtdbnode
          PODS=$(kubectl get pods -n cloud-benchmark -l app.kubernetes.io/component=benchmark,app.kubernetes.io/name=xtdb -o jsonpath='{.items[*].metadata.name}' || true)
          if [ -z "$PODS" ]; then
            # Fallback via plain text parsing
            PODS=$(kubectl get pods -n cloud-benchmark -l app.kubernetes.io/component=benchmark,app.kubernetes.io/name=xtdb -o name | sed 's#.*/##' || true)
          fi
          if [ -z "$PODS" ]; then
            echo "Failed to determine benchmark pods; skipping node debugging panel rendering"
            exit 0
          fi
          echo "Rendering node debugging panels for pods: $PODS"

          mkdir -p grafana-panels
          DASHBOARD_UID="edznf2lfly22o1aa" # XTDB: Node Debugging Dashboard
          FROM="${{ steps.grafana-time.outputs.from || 'now-2h' }}"
          TO="${{ steps.grafana-time.outputs.to || 'now' }}"
          WIDTH=1600
          HEIGHT=900
          SLUG="xtdb-node-debugging"

          declare -A PANELS=(
            ["JVM - Heap Usage (Average)"]=8
            ["JVM - Heap Usage (Max)"]=20
            ["JVM - Buffer Used"]=9
            ["JVM - Live Threads"]=10
            ["Transactions - Count"]=19
            ["Transactions - Timer (Max)"]=17
            ["Transactions - Timer (Quantiles)"]=16
            ["Query - Count"]=18
            ["Query - Timer (Max)"]=15
            ["Query - Timer (Quantiles)"]=14
            ["XTDB - Buffer Pool Allocated Memory"]=24
            ["XTDB - Compactor Allocated Memory"]=3
            ["Netty Allocated Memory"]=38
            ["Direct Allocated Memory"]=40
            ["Memory Cache - Record Batch count"]=26
            ["Buffer Pool - Record Batch requests"]=36
            ["Available Compaction Jobs"]=42
            ["Compaction Job Timer"]=45
          )

          slugify() {
            echo "$1" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g; s/^-+|-+$//g'
          }

          for node in $PODS; do
            for title in "${!PANELS[@]}"; do
              panelId="${PANELS[$title]}"
              file="grafana-panels/${node}-node-$(slugify "$title").png"
              url="http://localhost:3000/render/d-solo/${DASHBOARD_UID}/${SLUG}?panelId=${panelId}&orgId=1&from=${FROM}&to=${TO}&width=${WIDTH}&height=${HEIGHT}&tz=UTC&var-xtdbnode=${node}"
              echo "Rendering [Node Debug] $title (panelId=${panelId}, xtdbnode=${node}) -> $file"
              curl -sS -f -L -u "admin:${GRAFANA_ADMIN_PASSWORD}" -H 'Accept: image/png' "$url" -o "$file" || echo "Failed to render node panel $title for ${node}"
            done
          done

      - name: Upload Grafana Panels
        if: steps.check-deployment.outcome == 'success' && hashFiles('grafana-panels/*.png') != ''
        id: upload-grafana
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: grafana-panels-${{ inputs.benchType }}-${{ steps.timestamp.outputs.value }}-${{ inputs.nodeId }}-${{ inputs.status }}
          path: grafana-panels/*.png
          retention-days: 7

      - name: Stop Grafana Port-forward
        if: always()
        run: |
          if [ -f /tmp/grafana-pf.pid ]; then
            kill "$(cat /tmp/grafana-pf.pid)" 2>/dev/null || true
            rm -f /tmp/grafana-pf.pid
          fi

      - name: Gather Benchmark Image
        id: image-info
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          pod=$(kubectl get pods -n "$NS" -l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -z "$pod" ]; then
            echo "image=" >> "$GITHUB_OUTPUT"
            echo "image_repo=" >> "$GITHUB_OUTPUT"
            echo "image_tag=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          image=$(kubectl get pod "$pod" -n "$NS" -o jsonpath='{.spec.containers[?(@.name=="xtdb-node")].image}' 2>/dev/null || true)
          if [ -z "$image" ]; then
            echo "image=" >> "$GITHUB_OUTPUT"
            echo "image_repo=" >> "$GITHUB_OUTPUT"
            echo "image_tag=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if [[ "$image" == *:* ]]; then
            repo="${image%:*}"
            tag="${image##*:}"
          else
            repo="$image"
            tag=""
          fi
          echo "image=${image}" >> "$GITHUB_OUTPUT"
          echo "image_repo=${repo}" >> "$GITHUB_OUTPUT"
          echo "image_tag=${tag}" >> "$GITHUB_OUTPUT"

      - name: Gather Git Metadata from Job
        id: git-info
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          JOB_NAME="${{ inputs.benchType }}"

          # Get git metadata from the job annotations
          git_sha=$(kubectl get job "$JOB_NAME" -n "$NS" -o jsonpath='{.metadata.annotations.xtdb\.com/git-sha}' 2>/dev/null || true)
          git_branch=$(kubectl get job "$JOB_NAME" -n "$NS" -o jsonpath='{.metadata.annotations.xtdb\.com/git-branch}' 2>/dev/null || true)

          echo "sha=${git_sha}" >> "$GITHUB_OUTPUT"
          echo "branch=${git_branch}" >> "$GITHUB_OUTPUT"

          if [ -n "$git_sha" ] || [ -n "$git_branch" ]; then
            echo "Retrieved git metadata from job: branch=${git_branch}, sha=${git_sha}"
          else
            echo "No git metadata found on job"
          fi

      - name: Run Cleanup Script
        if: ${{ always() && steps.check-deployment.outcome == 'success' }}
        run: |
          ./modules/bench/cloud/clear-bench.sh azure

      - name: Remove Monitoring Stack
        if: always()
        run: |
          if helm status monitoring -n monitoring >/dev/null 2>&1; then
            echo "Uninstalling monitoring stack..."
            helm uninstall monitoring -n monitoring
            # Attempt to delete the namespace (ignore if it contains other resources or is already gone)
            kubectl delete namespace monitoring --ignore-not-found=true || true
          else
            echo "Monitoring stack not found; skipping."
          fi

      - name: Generate TPC-H Timeseries Chart
        id: timeseries-chart
        if: steps.check-deployment.outcome == 'success' && inputs.benchType == 'tpch' && steps.derive.outputs.bench_status == 'success'
        continue-on-error: true
        run: |
          set -euo pipefail
          # Install vega tools for chart generation
          npm install -g vega vega-lite vega-cli
          # Install rsvg-convert for SVG to PNG conversion (for Slack)
          sudo apt-get update && sudo apt-get install -y librsvg2-bin

          ./modules/bench/cloud/scripts/tasks plot-benchmark-timeseries tpch

          if [ -f tpch-benchmark-timeseries.svg ]; then
            echo "Generated TPC-H timeseries chart"
            echo "has_chart=true" >> "$GITHUB_OUTPUT"
            # Convert to PNG for Slack - use zoom to scale up while preserving aspect ratio
            rsvg-convert --zoom=2 tpch-benchmark-timeseries.svg -o tpch-benchmark-timeseries.png
          fi

      - name: Upload TPC-H Timeseries Chart
        if: steps.check-deployment.outcome == 'success' && inputs.benchType == 'tpch' && hashFiles('tpch-benchmark-timeseries.svg') != ''
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: tpch-timeseries-${{ steps.timestamp.outputs.value }}
          path: tpch-benchmark-timeseries.svg
          retention-days: 30

      - name: Write Job Summary
        if: always()
        run: |
          set -euo pipefail
          bench="${{ inputs.benchType }}"
          case "$bench" in
            tpch) bench_friendly="TPC-H" ;;
            auctionmark) bench_friendly="AuctionMark" ;;
            readings) bench_friendly="Readings" ;;
            yakbench) bench_friendly="Yakbench" ;;
            *) bench_friendly="$bench" ;;
          esac

          duration_iso="${{ steps.logs.outputs.time_taken_iso || '' }}"
          node_id="${{ inputs.nodeId }}"
          status_input="${{ steps.derive.outputs.bench_status || inputs.status }}"
          repo="${{ github.repository }}"
          run_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          scale_factor_val="${{ env.SCALE_FACTOR || '' }}"
          concurrency_val="${{ env.CONCURRENCY || '' }}"
          git_sha="${{ steps.git-info.outputs.sha || '' }}"
          git_branch="${{ steps.git-info.outputs.branch || '' }}"
          repo_url="${{ github.server_url }}/${{ github.repository }}"

          echo "# Benchmark Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Benchmark**: ${bench_friendly}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Status**: ${status_input}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Node ID**: ${node_id}" >> "$GITHUB_STEP_SUMMARY"
          if [ -n "$duration_iso" ]; then
            echo "- **Run duration**: ${duration_iso}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$scale_factor_val" ]; then
            echo "- **Scale factor**: ${scale_factor_val}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$concurrency_val" ]; then
            echo "- **Concurrency**: ${concurrency_val}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$git_branch" ]; then
            echo "- **Branch**: [${git_branch}](${repo_url}/tree/${git_branch})" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$git_sha" ]; then
            echo "- **Commit**: [${git_sha:0:7}](${repo_url}/commit/${git_sha})" >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "- **Repository**: ${repo}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          # Parameters (raw EDN captured, if any)
          if [ -n "${{ steps.logs.outputs.params_edn || '' }}" ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "## Raw Parameters (EDN)" >> "$GITHUB_STEP_SUMMARY"
            echo '```edn' >> "$GITHUB_STEP_SUMMARY"
            echo "${{ steps.logs.outputs.params_edn }}" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

          log_path="$(pwd)/benchmark.log"
          summary="$(./modules/bench/cloud/scripts/tasks summarize-log --format github "${{ inputs.benchType }}" "$log_path")"
          echo "## Query Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "$summary" >> "$GITHUB_STEP_SUMMARY"


      - name: Compose Slack Message
        id: compose
        run: |
          type="${{ inputs.benchType }}"
          [ "$type" = "tpch" ] && type="TPC-H"
          [ "$type" = "auctionmark" ] && type="AuctionMark"
          [ "$type" = "readings" ] && type="Readings"
          [ "$type" = "yakbench" ] && type="Yakbench"

          status="${{ steps.derive.outputs.bench_status || inputs.status }}"
          if [ "$status" = "success" ]; then
            status_emoji=":white_check_mark:"
            status_text="Passed"
          else
            status_emoji=":x:"
            status_text="Failed"
          fi

          log_path="$(pwd)/benchmark.log"
          summary="$(./modules/bench/cloud/scripts/tasks summarize-log --format slack "${{ inputs.benchType }}" "$log_path")"

          # Build base message
          if [ -n "${{ steps.logs.outputs.time_taken_iso }}" ]; then
            base="*${type} Benchmark* completed in ${{ steps.logs.outputs.time_taken_iso }} â€” ${status_emoji} ${status_text}"
          else
            base="*${type} Benchmark* completed â€” ${status_emoji} ${status_text}"
          fi

          IMAGE="${{ steps.image-info.outputs.image || '' }}"
          IMAGE_REPO="${{ steps.image-info.outputs.image_repo || '' }}"
          IMAGE_TAG="${{ steps.image-info.outputs.image_tag || '' }}"
          GIT_SHA="${{ steps.git-info.outputs.sha || '' }}"
          GIT_BRANCH="${{ steps.git-info.outputs.branch || '' }}"
          REPO_URL="${{ github.server_url }}/${{ github.repository }}"

          # Build git info line if we have metadata
          GIT_INFO=""
          if [ -n "$GIT_SHA" ] || [ -n "$GIT_BRANCH" ]; then
            SHORT_SHA="${GIT_SHA:0:7}"
            GIT_INFO_PARTS=()
            if [ -n "$GIT_BRANCH" ]; then
              GIT_INFO_PARTS+=("Branch: <${REPO_URL}/tree/${GIT_BRANCH}|\`${GIT_BRANCH}\`>")
            fi
            if [ -n "$GIT_SHA" ]; then
              GIT_INFO_PARTS+=("Commit: <${REPO_URL}/commit/${GIT_SHA}|\`${SHORT_SHA}\`>")
            fi
            GIT_INFO="${GIT_INFO_PARTS[0]}"
            for ((i=1; i<${#GIT_INFO_PARTS[@]}; i++)); do
              GIT_INFO="$GIT_INFO | ${GIT_INFO_PARTS[i]}"
            done
          fi

          # Build image info line if we have image metadata
          IMAGE_INFO=""
          if [ -n "$IMAGE" ]; then
            # Strip ghcr.io/ prefix for display
            IMAGE_DISPLAY="${IMAGE#ghcr.io/}"
            if [ -n "$IMAGE_REPO" ] && [ -n "$IMAGE_TAG" ]; then
              IMAGE_INFO="Image: <https://github.com/${{ github.repository_owner }}/xtdb-bench/pkgs/container/xtdb-bench|\`${IMAGE_DISPLAY}\`>"
            else
              IMAGE_INFO="Image: \`${IMAGE_DISPLAY}\`"
            fi
          fi

          {
            echo "msg<<EOF"
            echo "$base"
            if [ -n "$GIT_INFO" ]; then
              echo "$GIT_INFO"
            fi
            if [ -n "$IMAGE_INFO" ]; then
              echo "$IMAGE_INFO"
            fi
            if [ -n "$summary" ]; then
              echo ""
              echo "$summary"
            fi
            if [ "${{ steps.upload-logs.outcome }}" = "success" ] || [ "${{ steps.upload-grafana.outcome }}" = "success" ]; then
              echo ":link: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|view artifacts>"
            else
              echo ":link: (artifacts upload failed)"
            fi
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Prepare Slack Message
        if: steps.check-deployment.outcome == 'success'
        run: |
          jq -n --arg channel "$SLACK_CHANNEL" --arg text "$SLACK_MESSAGE" \
            '{channel: $channel, text: $text}' > slack-message.json
        env:
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
          SLACK_MESSAGE: ${{ steps.compose.outputs.msg }}

      - name: Post Slack Notification
        if: steps.check-deployment.outcome == 'success'
        uses: slackapi/slack-github-action@91efab103c0de0a537f72a35f6b8cda0ee76bf0a # v2.1.1
        with:
          method: chat.postMessage
          token: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          payload-file-path: ./slack-message.json

      - name: Post TPC-H Timeseries Chart to Slack
        if: steps.timeseries-chart.outputs.has_chart == 'true' && hashFiles('tpch-benchmark-timeseries.png') != ''
        env:
          SLACK_BOT_TOKEN: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
        run: |
          set -euo pipefail
          FILE_PATH="tpch-benchmark-timeseries.png"
          FILE_SIZE=$(stat -c%s "$FILE_PATH" 2>/dev/null || stat -f%z "$FILE_PATH")

          # Step 1: Get upload URL (using form data)
          UPLOAD_RESPONSE=$(curl -s \
            -H "Authorization: Bearer ${SLACK_BOT_TOKEN}" \
            -F "filename=tpch-benchmark-timeseries.png" \
            -F "length=${FILE_SIZE}" \
            https://slack.com/api/files.getUploadURLExternal)

          UPLOAD_URL=$(echo "$UPLOAD_RESPONSE" | jq -r '.upload_url')
          FILE_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.file_id')

          if [ "$UPLOAD_URL" = "null" ] || [ -z "$UPLOAD_URL" ]; then
            echo "Failed to get upload URL: $UPLOAD_RESPONSE"
            exit 1
          fi

          # Step 2: Upload file to the URL
          curl -s -X POST \
            -F "file=@${FILE_PATH}" \
            "$UPLOAD_URL"

          # Step 3: Complete the upload (using form data)
          FILES_JSON="[{\"id\":\"${FILE_ID}\",\"title\":\"TPC-H Performance Trend\"}]"
          curl -s \
            -H "Authorization: Bearer ${SLACK_BOT_TOKEN}" \
            -F "files=${FILES_JSON}" \
            -F "channel_id=${SLACK_CHANNEL}" \
            -F "initial_comment=ðŸ“ˆ TPC-H Benchmark Performance Trend (last 30 runs)" \
            https://slack.com/api/files.completeUploadExternal
