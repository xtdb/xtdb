name: Nightly Benchmark Cleanup
run-name: >-
  Benchmark Cleanup: ${{ inputs.benchType == 'tpch' && 'TPC-H' || inputs.benchType == 'auctionmark' && 'AuctionMark' || inputs.benchType == 'readings' && 'Readings' || inputs.benchType == 'yakbench' && 'Yakbench' || inputs.benchType == 'clickbench' && 'ClickBench' || inputs.benchType == 'tsbs-iot' && 'TSBS IoT' || inputs.benchType == 'ingest-tx-overhead' && 'Ingest TX Overhead' || inputs.benchType == 'patch' && 'Patch' || inputs.benchType == 'products' && 'Products' || inputs.benchType == 'ts-devices' && 'TS Devices' || inputs.benchType == 'fusion' && 'Fusion' || inputs.benchType }}

on:
  workflow_dispatch:
    inputs:
      benchType:
        description: 'Type of benchmark to clean up'
        required: true
        type: choice
        options:
          - tpch
          - auctionmark
          - readings
          - yakbench
          - clickbench
          - tsbs-iot
          - ingest-tx-overhead
          - patch
          - products
          - ts-devices
          - fusion
      status:
        description: 'Status of the benchmark'
        required: true
        type: choice
        options:
          - success
          - failure
      nodeId:
        description: 'Node ID of the benchmark'
        required: true
        type: string
      runQueue:
        description: 'Whether to dispatch the next benchmark in the nightly queue'
        required: false
        type: string

permissions:
  id-token: write
  contents: read
  actions: write

concurrency:
  group: cleanup-benchmarks
  cancel-in-progress: false

jobs:
  cleanup:
    runs-on: ubuntu-latest
    env:
      GRAFANA_ADMIN_PASSWORD: ${{ secrets.BENCHMARK_GRAFANA_ADMIN_PASSWORD }}
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v5

      - name: Install Babashka
        run: |
          set -euo pipefail
          BABASHKA_VERSION=1.12.209
          curl -sSfL "https://github.com/babashka/babashka/releases/download/v${BABASHKA_VERSION}/babashka-${BABASHKA_VERSION}-linux-amd64.tar.gz" -o /tmp/babashka.tar.gz
          sudo tar -xzf /tmp/babashka.tar.gz -C /usr/local/bin bb
          rm -f /tmp/babashka.tar.gz
          bb --version

      - name: Azure CLI Login
        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2
        with:
          client-id: ${{ secrets.BENCHMARK_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.BENCHMARK_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.BENCHMARK_AZURE_SUBSCRIPTION_ID }}

      - name: Acquire Kubernetes Configuration
        run: |
          az aks get-credentials --resource-group cloud-benchmark-resources --name xtdb-bench-cluster

      - name: Check Deployment
        id: check-deployment
        continue-on-error: true
        run: |
          # exit 0 if exists, non-zero if not
          helm status xtdb-benchmark -n cloud-benchmark >/dev/null 2>&1

      - name: Cancel workflow (no deployment found)
        if: steps.check-deployment.outcome != 'success'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            core.notice('No benchmark deployment found. Cancelling cleanup workflow run.');
            await github.rest.actions.cancelWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: context.runId,
            });

      - name: Stop job after cancellation
        if: steps.check-deployment.outcome != 'success'
        run: |
          echo "Cleanup workflow cancellation requested due to missing deployment. Stopping job."
          exit 0

      - name: Wait for Benchmark Job and Pods to Complete
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          result=$(./modules/bench/cloud/scripts/tasks wait-for-benchmark-completion "${{ inputs.benchType }}")
          echo "Wait result: $result"
          timed_out=$(echo "$result" | jq -r '.timedOut')
          if [ "$timed_out" = "true" ]; then
            echo "WARNING: Timed out waiting for job completion"
          fi

      - name: Determine Benchmark Status
        id: derive
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          result=$(./modules/bench/cloud/scripts/tasks derive-benchmark-status "${{ inputs.benchType }}")
          STATUS=$(echo "$result" | jq -r '.status')
          echo "bench_status=${STATUS}" >> "$GITHUB_OUTPUT"
          echo "Derived benchmark status: ${STATUS}"

      - name: Capture Benchmark Logs (All Pods)
        if: steps.check-deployment.outcome == 'success'
        id: logs
        run: |
          set -euo pipefail
          mkdir -p pod-logs

          result=$(./modules/bench/cloud/scripts/tasks capture-benchmark-logs "${{ inputs.benchType }}")

          # Write primary log to benchmark.log
          primary_log=$(echo "$result" | jq -r '.primaryLog // empty')
          if [ -n "$primary_log" ]; then
            echo "$primary_log" > benchmark.log
          fi

          # Write individual pod logs
          for pod in $(echo "$result" | jq -r '.logs | keys[]'); do
            log_content=$(echo "$result" | jq -r --arg pod "$pod" '.logs[$pod] // empty')
            if [ -n "$log_content" ]; then
              echo "$log_content" > "pod-logs/${pod}.log"
            fi
          done

          # Extract metrics
          params_edn=$(echo "$result" | jq -r '.paramsEdn // empty')
          if [ -n "$params_edn" ]; then
            {
              echo 'params_edn<<EOF'
              echo "$params_edn"
              echo 'EOF'
            } >> "$GITHUB_OUTPUT"
          fi

          sf=$(echo "$result" | jq -r '.scaleFactor // empty')
          if [ -n "$sf" ]; then
            echo "SCALE_FACTOR=${sf}" >> "$GITHUB_ENV"
          fi

          time_taken=$(echo "$result" | jq -r '.totalTimeMs // empty')
          if [ -n "$time_taken" ]; then
            echo "time_taken=${time_taken}" >> "$GITHUB_OUTPUT"
          fi

          time_iso=$(echo "$result" | jq -r '.timeTakenIso // empty')
          if [ -n "$time_iso" ]; then
            echo "time_taken_iso=${time_iso}" >> "$GITHUB_OUTPUT"
          fi

      - name: Capture Kubernetes Events
        if: steps.check-deployment.outcome == 'success'
        continue-on-error: true
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          mkdir -p pod-logs

          # Capture namespace events (sorted by last timestamp)
          echo "=== Kubernetes Events (namespace: ${NS}) ===" > pod-logs/kube-events.log
          kubectl get events -n "$NS" --sort-by='.lastTimestamp' >> pod-logs/kube-events.log 2>&1 || true

          # Capture pod descriptions (includes exit codes, OOMKill reasons, restarts)
          echo "" >> pod-logs/kube-events.log
          echo "=== Pod Descriptions ===" >> pod-logs/kube-events.log
          for pod in $(kubectl get pods -n "$NS" -l app.kubernetes.io/name=xtdb -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo "--- Pod: ${pod} ---" >> pod-logs/kube-events.log
            kubectl describe pod "$pod" -n "$NS" >> pod-logs/kube-events.log 2>&1 || true
          done

      - name: Set Timestamp
        id: timestamp
        run: |
          echo "value=$(date -u +"%Y-%m-%d-%H-%M-%S")" >> "$GITHUB_OUTPUT"
          echo "date=$(date -u +"%Y/%m/%d")" >> "$GITHUB_OUTPUT"

      - name: Upload Benchmark Logs
        id: upload-logs
        if: steps.check-deployment.outcome == 'success' && hashFiles('benchmark.log', 'pod-logs/*.log') != ''
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: benchmark-logs-${{ inputs.benchType }}-${{ steps.timestamp.outputs.value }}-${{ inputs.nodeId }}-${{ steps.derive.outputs.bench_status || inputs.status }}
          path: |
            pod-logs/*.log
          retention-days: 7

      - name: Compute Grafana Time Range
        id: grafana-time
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          result=$(./modules/bench/cloud/scripts/tasks compute-grafana-time-range benchmark.log)
          echo "from=$(echo "$result" | jq -r '.from')" >> "$GITHUB_OUTPUT"
          echo "to=$(echo "$result" | jq -r '.to')" >> "$GITHUB_OUTPUT"

      - name: Port-forward Grafana (background)
        if: steps.check-deployment.outcome == 'success'
        run: |
          # Start port-forward in background
          kubectl -n monitoring port-forward svc/monitoring-grafana 3000:80 >/tmp/grafana-pf.log 2>&1 &
          echo $! > /tmp/grafana-pf.pid
          # Wait for Grafana to be reachable
          for i in {1..30}; do
            if curl -sSf http://localhost:3000/api/health > /dev/null; then
              echo "Grafana is reachable"
              break
            fi
            echo "Waiting for Grafana port-forward... ($i)"
            sleep 2
          done

      - name: Render Cluster Monitoring Panels
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          mkdir -p grafana-panels
          DASHBOARD_UID="aeews5bgs0zk0b"
          FROM="${{ steps.grafana-time.outputs.from || 'now-2h' }}"
          TO="${{ steps.grafana-time.outputs.to || 'now' }}"
          WIDTH=1600
          HEIGHT=900
          SLUG="xtdb-monitoring-dashboard"

          # Declare panels: [title]=panelId
          declare -A PANELS=(
            ["# Nodes"]=1
            ["Transaction Lag"]=3
            ["Max Transaction Latency (Over Time)"]=5
            ["Max Query Latency (Over Time)"]=6
            ["Cluster Transactions"]=8
            ["Cluster Transactions Latencies"]=7
            ["Cluster Transaction Errors"]=22
            ["Cluster Queries"]=9
            ["Cluster Query Latencies"]=10
            ["Cluster Query Errors"]=20
            ["Cluster PGWire Active Connections"]=23
          )

          # Simple slugify for file names
          slugify() {
            echo "$1" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g; s/^-+|-+$//g'
          }

          for title in "${!PANELS[@]}"; do
            panelId="${PANELS[$title]}"
            file="grafana-panels/$(slugify "$title").png"
            url="http://localhost:3000/render/d-solo/${DASHBOARD_UID}/${SLUG}?panelId=${panelId}&orgId=1&from=${FROM}&to=${TO}&width=${WIDTH}&height=${HEIGHT}&tz=UTC"
            echo "Rendering [$title] (panelId=${panelId}) -> $file"
            curl -sS -f -L -u "admin:${GRAFANA_ADMIN_PASSWORD}" -H 'Accept: image/png' "$url" -o "$file" || echo "Failed to render $title"
          done

      - name: Render Node Debugging Panels
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          # Determine all XTDB node ids (pod names) to use for var-xtdbnode
          PODS=$(kubectl get pods -n cloud-benchmark -l app.kubernetes.io/component=benchmark,app.kubernetes.io/name=xtdb -o jsonpath='{.items[*].metadata.name}' || true)
          if [ -z "$PODS" ]; then
            # Fallback via plain text parsing
            PODS=$(kubectl get pods -n cloud-benchmark -l app.kubernetes.io/component=benchmark,app.kubernetes.io/name=xtdb -o name | sed 's#.*/##' || true)
          fi
          if [ -z "$PODS" ]; then
            echo "Failed to determine benchmark pods; skipping node debugging panel rendering"
            exit 0
          fi
          echo "Rendering node debugging panels for pods: $PODS"

          mkdir -p grafana-panels
          DASHBOARD_UID="edznf2lfly22o1aa" # XTDB: Node Debugging Dashboard
          FROM="${{ steps.grafana-time.outputs.from || 'now-2h' }}"
          TO="${{ steps.grafana-time.outputs.to || 'now' }}"
          WIDTH=1600
          HEIGHT=900
          SLUG="xtdb-node-debugging"

          declare -A PANELS=(
            ["JVM - Heap Usage (Average)"]=8
            ["JVM - Heap Usage (Max)"]=20
            ["JVM - Buffer Used"]=9
            ["JVM - Live Threads"]=10
            ["Transactions - Count"]=19
            ["Transactions - Timer (Max)"]=17
            ["Transactions - Timer (Quantiles)"]=16
            ["Query - Count"]=18
            ["Query - Timer (Max)"]=15
            ["Query - Timer (Quantiles)"]=14
            ["XTDB - Buffer Pool Allocated Memory"]=24
            ["XTDB - Compactor Allocated Memory"]=3
            ["Netty Allocated Memory"]=38
            ["Direct Allocated Memory"]=40
            ["Memory Cache - Record Batch count"]=26
            ["Buffer Pool - Record Batch requests"]=36
            ["Available Compaction Jobs"]=42
            ["Compaction Job Timer"]=45
          )

          slugify() {
            echo "$1" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g; s/^-+|-+$//g'
          }

          for node in $PODS; do
            for title in "${!PANELS[@]}"; do
              panelId="${PANELS[$title]}"
              file="grafana-panels/${node}-node-$(slugify "$title").png"
              url="http://localhost:3000/render/d-solo/${DASHBOARD_UID}/${SLUG}?panelId=${panelId}&orgId=1&from=${FROM}&to=${TO}&width=${WIDTH}&height=${HEIGHT}&tz=UTC&var-xtdbnode=${node}"
              echo "Rendering [Node Debug] $title (panelId=${panelId}, xtdbnode=${node}) -> $file"
              curl -sS -f -L -u "admin:${GRAFANA_ADMIN_PASSWORD}" -H 'Accept: image/png' "$url" -o "$file" || echo "Failed to render node panel $title for ${node}"
            done
          done

      - name: Upload Grafana Panels
        if: steps.check-deployment.outcome == 'success' && hashFiles('grafana-panels/*.png') != ''
        id: upload-grafana
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: grafana-panels-${{ inputs.benchType }}-${{ steps.timestamp.outputs.value }}-${{ inputs.nodeId }}-${{ inputs.status }}
          path: grafana-panels/*.png
          retention-days: 7

      - name: Stop Grafana Port-forward
        if: always()
        run: |
          if [ -f /tmp/grafana-pf.pid ]; then
            kill "$(cat /tmp/grafana-pf.pid)" 2>/dev/null || true
            rm -f /tmp/grafana-pf.pid
          fi

      - name: Gather Benchmark Image
        id: image-info
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          pod=$(kubectl get pods -n "$NS" -l app.kubernetes.io/name=xtdb,app.kubernetes.io/component=benchmark -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -z "$pod" ]; then
            echo "image=" >> "$GITHUB_OUTPUT"
            echo "image_repo=" >> "$GITHUB_OUTPUT"
            echo "image_tag=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          image=$(kubectl get pod "$pod" -n "$NS" -o jsonpath='{.spec.containers[?(@.name=="xtdb-node")].image}' 2>/dev/null || true)
          if [ -z "$image" ]; then
            echo "image=" >> "$GITHUB_OUTPUT"
            echo "image_repo=" >> "$GITHUB_OUTPUT"
            echo "image_tag=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if [[ "$image" == *:* ]]; then
            repo="${image%:*}"
            tag="${image##*:}"
          else
            repo="$image"
            tag=""
          fi
          echo "image=${image}" >> "$GITHUB_OUTPUT"
          echo "image_repo=${repo}" >> "$GITHUB_OUTPUT"
          echo "image_tag=${tag}" >> "$GITHUB_OUTPUT"

      - name: Gather Git Metadata from Job
        id: git-info
        if: steps.check-deployment.outcome == 'success'
        run: |
          set -euo pipefail
          NS="cloud-benchmark"
          JOB_NAME="${{ inputs.benchType }}"

          # Get git metadata from the job annotations
          git_sha=$(kubectl get job "$JOB_NAME" -n "$NS" -o jsonpath='{.metadata.annotations.xtdb\.com/git-sha}' 2>/dev/null || true)
          git_branch=$(kubectl get job "$JOB_NAME" -n "$NS" -o jsonpath='{.metadata.annotations.xtdb\.com/git-branch}' 2>/dev/null || true)

          echo "sha=${git_sha}" >> "$GITHUB_OUTPUT"
          echo "branch=${git_branch}" >> "$GITHUB_OUTPUT"

          if [ -n "$git_sha" ] || [ -n "$git_branch" ]; then
            echo "Retrieved git metadata from job: branch=${git_branch}, sha=${git_sha}"
          else
            echo "No git metadata found on job"
          fi

      - name: Re-authenticate Azure CLI (before rescue)
        if: steps.check-deployment.outcome == 'success'
        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2
        with:
          client-id: ${{ secrets.BENCHMARK_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.BENCHMARK_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.BENCHMARK_AZURE_SUBSCRIPTION_ID }}

      - name: Rescue Crash Dumps
        if: steps.check-deployment.outcome == 'success'
        continue-on-error: true
        run: |
          set -euo pipefail
          STORAGE_ACCOUNT="xtdbazurebenchmark"
          SRC_CONTAINER="xtdbazurebenchmarkcontainer"
          DST_CONTAINER="xtdb-crash-dumps"

          # Check if there are any dumps to rescue (heap dumps or XTDB crash logs)
          HEAP_COUNT=$(az storage blob list \
            --auth-mode login \
            --account-name "$STORAGE_ACCOUNT" \
            --container-name "$SRC_CONTAINER" \
            --prefix "dumps/" \
            --query "length(@)" \
            --output tsv 2>/dev/null || echo "0")

          CRASH_COUNT=$(az storage blob list \
            --auth-mode login \
            --account-name "$STORAGE_ACCOUNT" \
            --container-name "$SRC_CONTAINER" \
            --prefix "xtdb-object-store/crashes/" \
            --query "length(@)" \
            --output tsv 2>/dev/null || echo "0")

          TOTAL_COUNT=$((HEAP_COUNT + CRASH_COUNT))
          if [ "$TOTAL_COUNT" = "0" ]; then
            echo "No crash artifacts to rescue (heap dumps: $HEAP_COUNT, crash logs: $CRASH_COUNT)"
            exit 0
          fi

          echo "Found crash artifacts to rescue (heap dumps: $HEAP_COUNT, crash logs: $CRASH_COUNT)"

          # Ensure destination container exists
          az storage container create \
            --auth-mode login \
            --account-name "$STORAGE_ACCOUNT" \
            --name "$DST_CONTAINER" \
            --public-access off 2>/dev/null || true

          # Copy dumps to safe container with timestamp prefix
          TIMESTAMP=$(date -u +"%Y-%m-%d/%H-%M-%S")
          BENCH_TYPE="${{ inputs.benchType }}"

          # Rescue heap dumps (from dump-uploader sidecar)
          az storage blob copy start-batch \
            --auth-mode login \
            --account-name "$STORAGE_ACCOUNT" \
            --source-container "$SRC_CONTAINER" \
            --destination-container "$DST_CONTAINER" \
            --pattern "dumps/*" \
            --destination-path "$TIMESTAMP/$BENCH_TYPE" || true

          # Rescue XTDB crash logs (from crash-log! in indexer)
          az storage blob copy start-batch \
            --auth-mode login \
            --account-name "$STORAGE_ACCOUNT" \
            --source-container "$SRC_CONTAINER" \
            --destination-container "$DST_CONTAINER" \
            --pattern "xtdb-object-store/crashes/*" \
            --destination-path "$TIMESTAMP/$BENCH_TYPE" || true

          echo "Crash artifacts rescued to $DST_CONTAINER/$TIMESTAMP/$BENCH_TYPE/"

      - name: Re-authenticate Azure CLI (before cleanup)
        if: ${{ always() && steps.check-deployment.outcome == 'success' }}
        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2
        with:
          client-id: ${{ secrets.BENCHMARK_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.BENCHMARK_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.BENCHMARK_AZURE_SUBSCRIPTION_ID }}

      - name: Run Cleanup Script
        if: ${{ always() && steps.check-deployment.outcome == 'success' }}
        run: |
          ./modules/bench/cloud/clear-bench.sh azure

      - name: Remove Monitoring Stack
        if: always()
        run: |
          if helm status monitoring -n monitoring >/dev/null 2>&1; then
            echo "Uninstalling monitoring stack..."
            helm uninstall monitoring -n monitoring
            # Attempt to delete the namespace (ignore if it contains other resources or is already gone)
            kubectl delete namespace monitoring --ignore-not-found=true || true
          else
            echo "Monitoring stack not found; skipping."
          fi

      - name: Generate Benchmark Timeseries Chart
        id: timeseries-chart
        if: steps.check-deployment.outcome == 'success' && steps.derive.outputs.bench_status == 'success'
        continue-on-error: true
        env:
          SCALE_FACTOR: ${{ env.SCALE_FACTOR }}
        run: |
          set -euo pipefail
          BENCH_TYPE="${{ inputs.benchType }}"

          # Install vega tools for chart generation
          npm install -g vega vega-lite vega-cli
          # Install rsvg-convert for SVG to PNG conversion (for Slack)
          sudo apt-get update && sudo apt-get install -y librsvg2-bin

          # Build command with optional scale-factor
          CMD_ARGS=("plot-benchmark-timeseries")
          if [ -n "$SCALE_FACTOR" ]; then
            CMD_ARGS+=("--scale-factor" "$SCALE_FACTOR")
          fi
          CMD_ARGS+=("$BENCH_TYPE")

          ./modules/bench/cloud/scripts/tasks "${CMD_ARGS[@]}"

          SVG_FILE="${BENCH_TYPE}-benchmark-timeseries.svg"
          PNG_FILE="${BENCH_TYPE}-benchmark-timeseries.png"

          if [ -f "$SVG_FILE" ]; then
            echo "Generated ${BENCH_TYPE} timeseries chart"
            echo "has_chart=true" >> "$GITHUB_OUTPUT"
            echo "svg_file=${SVG_FILE}" >> "$GITHUB_OUTPUT"
            echo "png_file=${PNG_FILE}" >> "$GITHUB_OUTPUT"
            # Convert to PNG for Slack - use zoom to scale up while preserving aspect ratio
            rsvg-convert --zoom=2 "$SVG_FILE" -o "$PNG_FILE"
          fi

      - name: Upload Benchmark Timeseries Chart
        if: steps.check-deployment.outcome == 'success' && steps.timeseries-chart.outputs.has_chart == 'true'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: ${{ inputs.benchType }}-timeseries-${{ steps.timestamp.outputs.value }}
          path: ${{ steps.timeseries-chart.outputs.svg_file }}
          retention-days: 30

      - name: Write Job Summary
        if: always()
        run: |
          set -euo pipefail
          bench="${{ inputs.benchType }}"
          case "$bench" in
            tpch) bench_friendly="TPC-H" ;;
            auctionmark) bench_friendly="AuctionMark" ;;
            readings) bench_friendly="Readings" ;;
            yakbench) bench_friendly="Yakbench" ;;
            patch) bench_friendly="Patch" ;;
            products) bench_friendly="Products" ;;
            ts-devices) bench_friendly="TS Devices" ;;
            fusion) bench_friendly="Fusion" ;;
            *) bench_friendly="$bench" ;;
          esac

          duration_iso="${{ steps.logs.outputs.time_taken_iso || '' }}"
          node_id="${{ inputs.nodeId }}"
          status_input="${{ steps.derive.outputs.bench_status || inputs.status }}"
          repo="${{ github.repository }}"
          run_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          scale_factor_val="${{ env.SCALE_FACTOR || '' }}"
          concurrency_val="${{ env.CONCURRENCY || '' }}"
          git_sha="${{ steps.git-info.outputs.sha || '' }}"
          git_branch="${{ steps.git-info.outputs.branch || '' }}"
          repo_url="${{ github.server_url }}/${{ github.repository }}"

          echo "# Benchmark Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Benchmark**: ${bench_friendly}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Status**: ${status_input}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Node ID**: ${node_id}" >> "$GITHUB_STEP_SUMMARY"
          if [ -n "$duration_iso" ]; then
            echo "- **Run duration**: ${duration_iso}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$scale_factor_val" ]; then
            echo "- **Scale factor**: ${scale_factor_val}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$concurrency_val" ]; then
            echo "- **Concurrency**: ${concurrency_val}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$git_branch" ]; then
            echo "- **Branch**: [${git_branch}](${repo_url}/tree/${git_branch})" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [ -n "$git_sha" ]; then
            echo "- **Commit**: [${git_sha:0:7}](${repo_url}/commit/${git_sha})" >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "- **Repository**: ${repo}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          # Parameters (raw EDN captured, if any)
          if [ -n "${{ steps.logs.outputs.params_edn || '' }}" ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "## Raw Parameters (EDN)" >> "$GITHUB_STEP_SUMMARY"
            echo '```edn' >> "$GITHUB_STEP_SUMMARY"
            echo "${{ steps.logs.outputs.params_edn }}" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

          log_path="$(pwd)/benchmark.log"
          if [ -f "$log_path" ]; then
            summary="$(./modules/bench/cloud/scripts/tasks summarize-log --format github "${{ inputs.benchType }}" "$log_path" 2>&1)" || summary=""
            if [ -n "$summary" ]; then
              echo "## Query Summary" >> "$GITHUB_STEP_SUMMARY"
              echo "$summary" >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "## Query Summary" >> "$GITHUB_STEP_SUMMARY"
            echo "_No benchmark log available_" >> "$GITHUB_STEP_SUMMARY"
          fi


      - name: Compose Slack Message
        id: compose
        run: |
          type="${{ inputs.benchType }}"
          [ "$type" = "tpch" ] && type="TPC-H"
          [ "$type" = "auctionmark" ] && type="AuctionMark"
          [ "$type" = "readings" ] && type="Readings"
          [ "$type" = "yakbench" ] && type="Yakbench"
          [ "$type" = "patch" ] && type="Patch"
          [ "$type" = "products" ] && type="Products"
          [ "$type" = "ts-devices" ] && type="TS Devices"
          [ "$type" = "fusion" ] && type="Fusion"

          status="${{ steps.derive.outputs.bench_status || inputs.status }}"
          if [ "$status" = "success" ]; then
            status_emoji=":white_check_mark:"
            status_text="Passed"
          else
            status_emoji=":x:"
            status_text="Failed"
          fi

          log_path="$(pwd)/benchmark.log"
          summary=""
          timeout_detected=false
          timeout_duration=""
          if [ -f "$log_path" ]; then
            summary="$(./modules/bench/cloud/scripts/tasks summarize-log --format slack "${{ inputs.benchType }}" "$log_path" 2>&1)" || summary=""
            # Check for timeout in log
            if grep -q "Benchmark exceeded timeout" "$log_path"; then
              timeout_detected=true
              timeout_duration=$(grep -o "exceeded timeout ([^)]*)" "$log_path" | head -1 | sed 's/exceeded timeout (\(.*\))/\1/')
            fi
          fi

          # Build base message - different wording for timeout vs completion
          if [ "$timeout_detected" = "true" ]; then
            # For timeouts, don't show the misleading partial duration
            base="*${type} Benchmark* :hourglass: timed out after ${timeout_duration:-unknown} — ${status_emoji} ${status_text}"
          elif [ -n "${{ steps.logs.outputs.time_taken_iso }}" ]; then
            base="*${type} Benchmark* completed in ${{ steps.logs.outputs.time_taken_iso }} — ${status_emoji} ${status_text}"
          else
            base="*${type} Benchmark* completed — ${status_emoji} ${status_text}"
          fi

          IMAGE="${{ steps.image-info.outputs.image || '' }}"
          IMAGE_REPO="${{ steps.image-info.outputs.image_repo || '' }}"
          IMAGE_TAG="${{ steps.image-info.outputs.image_tag || '' }}"
          GIT_SHA="${{ steps.git-info.outputs.sha || '' }}"
          GIT_BRANCH="${{ steps.git-info.outputs.branch || '' }}"
          REPO_URL="${{ github.server_url }}/${{ github.repository }}"

          # Build git info line if we have metadata
          GIT_INFO=""
          if [ -n "$GIT_SHA" ] || [ -n "$GIT_BRANCH" ]; then
            SHORT_SHA="${GIT_SHA:0:7}"
            GIT_INFO_PARTS=()
            if [ -n "$GIT_BRANCH" ]; then
              GIT_INFO_PARTS+=("Branch: <${REPO_URL}/tree/${GIT_BRANCH}|\`${GIT_BRANCH}\`>")
            fi
            if [ -n "$GIT_SHA" ]; then
              GIT_INFO_PARTS+=("Commit: <${REPO_URL}/commit/${GIT_SHA}|\`${SHORT_SHA}\`>")
            fi
            GIT_INFO="${GIT_INFO_PARTS[0]}"
            for ((i=1; i<${#GIT_INFO_PARTS[@]}; i++)); do
              GIT_INFO="$GIT_INFO | ${GIT_INFO_PARTS[i]}"
            done
          fi

          # Build image info line if we have image metadata
          IMAGE_INFO=""
          if [ -n "$IMAGE" ]; then
            # Strip ghcr.io/ prefix for display
            IMAGE_DISPLAY="${IMAGE#ghcr.io/}"
            if [ -n "$IMAGE_REPO" ] && [ -n "$IMAGE_TAG" ]; then
              IMAGE_INFO="Image: <https://github.com/${{ github.repository_owner }}/xtdb-bench/pkgs/container/xtdb-bench|\`${IMAGE_DISPLAY}\`>"
            else
              IMAGE_INFO="Image: \`${IMAGE_DISPLAY}\`"
            fi
          fi

          {
            echo "msg<<EOF"
            echo "$base"
            if [ -n "$GIT_INFO" ]; then
              echo "$GIT_INFO"
            fi
            if [ -n "$IMAGE_INFO" ]; then
              echo "$IMAGE_INFO"
            fi
            # Split summary on delimiter if present (for benchmarks with large output)
            summary_main="$summary"
            summary_extra=""
            if [[ "$summary" == *"---SLACK-SPLIT---"* ]]; then
              summary_main="${summary%%---SLACK-SPLIT---*}"
              summary_extra="${summary#*---SLACK-SPLIT---}"
              # Trim leading/trailing whitespace
              summary_extra="$(echo "$summary_extra" | sed 's/^[[:space:]]*//' | sed 's/[[:space:]]*$//')"
            fi

            if [ -n "$summary_main" ]; then
              echo ""
              echo "$summary_main"
            fi
            if [ "${{ steps.upload-logs.outcome }}" = "success" ] || [ "${{ steps.upload-grafana.outcome }}" = "success" ]; then
              echo ":link: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|view artifacts>"
            else
              echo ":link: (artifacts upload failed)"
            fi
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

          # Store extra summary for follow-up message
          if [ -n "$summary_extra" ]; then
            {
              echo "msg_extra<<EOF"
              echo "$summary_extra"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          fi

      - name: Prepare Slack Message
        if: steps.check-deployment.outcome == 'success'
        run: |
          jq -n --arg channel "$SLACK_CHANNEL" --arg text "$SLACK_MESSAGE" \
            '{channel: $channel, text: $text}' > slack-message.json
        env:
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
          SLACK_MESSAGE: ${{ steps.compose.outputs.msg }}

      - name: Post Slack Notification
        if: steps.check-deployment.outcome == 'success'
        uses: slackapi/slack-github-action@91efab103c0de0a537f72a35f6b8cda0ee76bf0a # v2.1.1
        with:
          method: chat.postMessage
          token: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          payload-file-path: ./slack-message.json

      - name: Post Slack Continuation
        if: steps.check-deployment.outcome == 'success' && steps.compose.outputs.msg_extra != ''
        run: |
          jq -n --arg channel "$SLACK_CHANNEL" --arg text "$SLACK_MESSAGE" \
            '{channel: $channel, text: $text}' > slack-message-extra.json
        env:
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
          SLACK_MESSAGE: ${{ steps.compose.outputs.msg_extra }}

      - name: Post Slack Continuation Message
        if: steps.check-deployment.outcome == 'success' && steps.compose.outputs.msg_extra != ''
        uses: slackapi/slack-github-action@91efab103c0de0a537f72a35f6b8cda0ee76bf0a # v2.1.1
        with:
          method: chat.postMessage
          token: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          payload-file-path: ./slack-message-extra.json

      - name: Post Benchmark Timeseries Chart to Slack
        if: steps.timeseries-chart.outputs.has_chart == 'true'
        env:
          SLACK_BOT_TOKEN: ${{ secrets.BENCHMARK_SLACK_BOT_TOKEN }}
          SLACK_CHANNEL: ${{ secrets.BENCHMARK_SLACK_CHANNEL_ID }}
          BENCH_TYPE: ${{ inputs.benchType }}
          PNG_FILE: ${{ steps.timeseries-chart.outputs.png_file }}
        run: |
          set -euo pipefail

          # Map benchmark type to friendly name
          case "$BENCH_TYPE" in
            tpch) FRIENDLY_NAME="TPC-H" ;;
            auctionmark) FRIENDLY_NAME="AuctionMark" ;;
            readings) FRIENDLY_NAME="Readings" ;;
            yakbench) FRIENDLY_NAME="Yakbench" ;;
            patch) FRIENDLY_NAME="Patch" ;;
            products) FRIENDLY_NAME="Products" ;;
            ts-devices) FRIENDLY_NAME="TS Devices" ;;
            fusion) FRIENDLY_NAME="Fusion" ;;
            *) FRIENDLY_NAME="$BENCH_TYPE" ;;
          esac

          FILE_PATH="$PNG_FILE"
          if [ ! -f "$FILE_PATH" ]; then
            echo "Chart file not found: $FILE_PATH"
            exit 1
          fi

          FILE_SIZE=$(stat -c%s "$FILE_PATH" 2>/dev/null || stat -f%z "$FILE_PATH")

          # Step 1: Get upload URL (using form data)
          UPLOAD_RESPONSE=$(curl -s \
            -H "Authorization: Bearer ${SLACK_BOT_TOKEN}" \
            -F "filename=${PNG_FILE}" \
            -F "length=${FILE_SIZE}" \
            https://slack.com/api/files.getUploadURLExternal)

          UPLOAD_URL=$(echo "$UPLOAD_RESPONSE" | jq -r '.upload_url')
          FILE_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.file_id')

          if [ "$UPLOAD_URL" = "null" ] || [ -z "$UPLOAD_URL" ]; then
            echo "Failed to get upload URL: $UPLOAD_RESPONSE"
            exit 1
          fi

          # Step 2: Upload file to the URL
          curl -s -X POST \
            -F "file=@${FILE_PATH}" \
            "$UPLOAD_URL"

          # Step 3: Complete the upload (using form data)
          FILES_JSON="[{\"id\":\"${FILE_ID}\",\"title\":\"${FRIENDLY_NAME} Performance Trend\"}]"
          curl -s \
            -H "Authorization: Bearer ${SLACK_BOT_TOKEN}" \
            -F "files=${FILES_JSON}" \
            -F "channel_id=${SLACK_CHANNEL}" \
            -F "initial_comment=${FRIENDLY_NAME} Benchmark Performance Trend (last 30 runs)" \
            https://slack.com/api/files.completeUploadExternal

      - name: Dispatch Next Benchmark in Queue
        if: always() && inputs.runQueue == 'true' && steps.check-deployment.outcome == 'success'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const queue = [
              'tpch', 'yakbench', 'readings', 'auctionmark',
              'clickbench', 'tsbs-iot', 'ingest-tx-overhead',
              'patch', 'products', 'ts-devices', 'fusion'
            ];
            const current = '${{ inputs.benchType }}';
            const idx = queue.indexOf(current);
            if (idx >= 0 && idx < queue.length - 1) {
              const next = queue[idx + 1];
              await github.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: `nightly-benchmark-${next}.yml`,
                ref: '${{ github.ref_name }}',
                inputs: { run_queue: 'true' }
              });
              core.info(`Dispatched next benchmark: ${next} (${idx + 2}/${queue.length})`);
            } else {
              core.info('Queue complete - all benchmarks dispatched');
            }
