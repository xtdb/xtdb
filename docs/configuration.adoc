[#configuration]
= Configuration
[#config-nodes]
== Nodes

To start a Crux node, use the
https://juxt.pro/crux/docs/javadoc/index.html[Java API] or the Clojure
https://github.com/juxt/crux/blob/master/crux-core/src/crux/api.clj[`crux.api`].

Within Clojure, we call `start-node` from within `crux.api`, passing it a set of
options for the node. There are a number of different configuration options a Crux node
can have, grouped into *topologies*.

.Crux Topologies
[#table-conversion%header,cols="d,d,d"]
|===
|Name|Transaction Log|Topology
|<<#config-standalone, Standalone>>|Uses local event log|`:crux.standalone/topology`
|<<#config-kafka, Kafka>>|Uses Kafka|`:crux.kafka/topology`
|<<#config-jdbc, JDBC>>|Uses JDBC event log|`:crux.jdbc/topology`
|===

Use a Kafka node when horizontal scalability is required or when
you want the guarantees that Kafka offers in terms of resiliency,
availability and retention of data.

Multiple Kafka nodes participate in a cluster with Kafka as the primary
store and as the central means of coordination.

The JDBC node is useful when you don't want the overhead of maintaining a
Kafka cluster. Read more about the motivations of this setup
https://juxt.pro/blog/posts/crux-jdbc.html[here].

The Standalone node is a single Crux instance which has everything
it needs locally. This is good for experimenting with Crux and
for small to medium sized deployments, where running a single instance
is permissible.

Crux nodes implement the `ICruxAPI` interface and are the
starting point for making use of Crux. Nodes also implement
`java.io.Closeable` and can therefore be lifecycle managed.

[#config-properties]
== Properties

The following properties are within the topology used as a base
for the other topologies, `crux.node`:

.`crux.node` configuration
[#table-conversion%header,cols="d,d"]
|===
|Property|Default Value
|`:crux.node/kv-store`|*`'crux.kv.rocksdb/kv`*
|`:crux.node/object-store`|*`'crux.object-store/kv-object-store`*
|===

The following set of options are used by KV backend implementations,
defined within `crux.kv`:

.`crux.kv` options
[#table-conversion%header,cols="d,d,d"]
|===
|Property|Description|Default Value
|`:crux.kv/db-dir` | Directory to store K/V files | *data*
|`:crux.kv/sync?`| Sync the KV store to disk after every write?| *false*
|`:crux.kv/check-and-store-index-version` | Check and store index version upon start? | *true*
|===


[#config-standalone]
== Standalone Node

Using a Crux standalone node is the best way to get started. Once
you've started a standalone Crux instance as described below, you can
then follow the <<#get_started,getting started
example>>.

image::local-standalone-mode.svg?sanitize=true[Local Standalone Mode,width=70%,align="center"]

.Standalone configuration
[#table-conversion%header,cols="d,d,d"]
|===
|Property|Description|Default Value
|`:crux.standalone/event-log-kv-store` | Key/Value store to use for standalone event-log persistence | *'crux.kv.rocksdb/kv*
|`:crux.standalone/event-log-dir`| Directory used to store the event-log and used for backup/restore, i.e. `"data/eventlog-1"`|
|`:crux.standalone/event-log-sync?` | Sync the event-log backend KV store to disk after every write? | *false*
|===
[#standalone-dependency]
*Project Dependency*

[source,clj]
----
include::./deps.edn[tags=CruxDep]
----
[#standalone-start]
*Getting started*

The following code creates a node which runs completely within memory (with both the event-log store and db store using `crux.kv.memdb/kv`):
[source,clj]
----
include::./src/docs/examples.clj[tags=include-crux-api]

include::./src/docs/examples.clj[tags=start-standalone-node]
----

You can later stop the node if you wish:

[source,clj]
----
include::./src/docs/examples.clj[tags=close-node]
----

[#config-rocksdb]
== RocksDB

RocksDB is used, by default, as Crux's primary store (in place of the in memory kv store in the example above).
In order to use RocksDB within crux, however, you must first add RocksDB as a project dependency:

[#rocksdep]
*Project Dependency*

[source,clj,subs="normal"]
----
include::./deps.edn[tags=RocksDeps]
----

[#rocks-start]
*Starting a node using RocksDB*

[source,clj]
----
include::./src/docs/examples.clj[tags=start-standalone-with-rocks]
----

You can create a node with custom RocksDB options by passing extra keywords in the topology. These are:

* `:crux.kv.rocksdb/disable-wal?`, which takes a boolean (if true, disables the *write ahead log*)
* `:crux.kv.rocksdb/db-options`, which takes a RocksDB 'Options' object (see more https://javadoc.io/doc/org.rocksdb/rocksdbjni/6.2.2/org/rocksdb/Options.html[here], from the *RocksDB javadocs*)

== LMDB

An alternative to RocksDB, LMDB provides faster queries in exchange for a slower ingest rate.

[#lmdbdep]
*Project Dependency*

[source,clj,subs="normal"]
----
include::./deps.edn[tags=LMDBDeps]
----

[#rocks-start]
*Starting a node using LMDB*

[source,clj]
----
include::./src/docs/examples.clj[tags=start-standalone-with-lmdb]
----

[#config-kafka]
== Kafka Nodes

When using Crux at scale it is recommended to use multiple Crux nodes connected
via a Kafka cluster.

image::local-cluster-mode.svg?sanitize=true[Local Cluster Mode,width=70%,align="center"]

Kafka nodes have the following properties:

.Kafka node configuration
[#table-conversion%header,cols="d,d,d"]
|===
|Property|Description|Default value
|`:crux.kafka/bootstrap-servers`|URL for connecting to Kafka|*localhost:9092*
|`:crux.kafka/tx-topic`|Name of Kafka transaction log topic|*crux-transaction-log*
|`:crux.kafka/doc-topic`|Name of Kafka documents topic|*crux-docs*
|`:crux.kafka/create-topics`|Option to automatically create Kafka topics if they do not already exist|*true*
|`:crux.kafka/doc-partitions`|Number of partitions for the document topic|*1*
|`:crux.kafka/replication-factor`|Number of times to replicate data on Kafka|*1*
|`:crux.kafka/kafka-properties-file`|File to supply Kafka connection properties to the underlying Kafka API|
|`:crux.kafka/kafka-properties-map`|Map to supply Kafka connection properties to the underlying Kafka API|
|===

[#kafka-dependency]
*Project Dependencies*

[source,clj]
----
include::./deps.edn[tags=CruxDep]
include::./deps.edn[tags=KafkaClientsDeps]
----

[#kafka-start]
*Getting started*

Use the API to start a Kafka node, configuring it with the
`bootstrap-servers` property in order to connect to Kafka:

[source,clj]
----
include::./src/docs/examples.clj[tags=start-cluster-node]
----

NOTE: If you don't specify `kv-store` then by default the
Kafka node will use RocksDB. You will need to <<#rocksdep,add RocksDB>> to
your list of project dependencies.

You can later stop the node if you wish:

[source,clj]
----
include::./src/docs/examples.clj[tags=close-node]
----

[#kafka-embed]
=== Embedded Kafka

Crux is ready to work with an embedded Kafka for when you don't have an independently
running Kafka available to connect to (such as during development).

[#embedded-kafka-dependency]
*Project Depencies*

[source,clj,subs="normal"]
----
include::./deps.edn[tags=CruxDep]
include::./deps.edn[tags=KafkaEmbeddedDeps]
----

[#embedded-kafka-start]
*Getting started*

[source,clj]
----
include::./src/docs/examples.clj[tags=require-ek]

include::./src/docs/examples.clj[tags=ek-example]
----

You can later stop the Embedded Kafka if you wish:

[source,clj]
----
include::./src/docs/examples.clj[tags=ek-close]
----

[#config-jdbc]
== JDBC Nodes

JDBC Nodes use https://github.com/seancorfield/next-jdbc/[`next.jdbc`]
internally and pass through the relevant configuration options that
you can find
https://github.com/seancorfield/next-jdbc/blob/master/doc/all-the-options.md[here].

image::jdbc-modes.svg?sanitize=true[Local Cluster Mode,width=70%,align="center"]

Below is the minimal configuration you will need:

.Minimal JDBC Configuration
[#table-conversion%header,cols="d,d"]
|===
|Property|Description
|`:crux.jdbc/dbtype`|One of: *postgresql*, *oracle*, *mysql*, *h2*, *sqlite*
|`:crux.jdbc/dbname`|Database Name
|===

Depending on the type of JDBC database used, you may also need some of the following properties:

.Other JDBC Properties
[#table-conversion%header,cols="d,d"]
|===
|Property|Description
|`:crux.kv/db-dir`|_For h2 and sqlite_
|`:crux.jdbc/host`|Database Host
|`:crux.jdbc/user`|Database Username
|`:crux.jdbc/password`|Database Password
|===

[#jdbc-dependency]
*Project Dependencies*

[source,clj]
----
include::./deps.edn[tags=CruxDep]
include::./deps.edn[tags=JDBCDeps]
----

[#jdbc-start]
*Getting started*

Use the API to start a JDBC node, configuring it with the required
parameters:

[source,clj]
----
include::./src/docs/examples.clj[tags=start-jdbc-node]
----

[#config-http]
== HTTP

Crux can be used programmatically as a library, but Crux also ships
with an embedded HTTP server, that allows clients to use the API
remotely via REST.

image::remote-cluster-mode.svg?sanitize=true[Remote Cluster Mode,width=70%,align="center"]

Set the `server-port` configuration property on a Crux node to
expose a HTTP port that will accept REST requests:

.HTTP Nodes Configuration
[#table-conversion%header,cols="d,d,d"]
|===
|Component|Property|Description
|crux.http-server|`port`|Port for Crux HTTP Server e.g. `8080`
|===

Visit the guide on using the <<#rest,REST api>> for examples
of how to interact with Crux over HTTP.
[#config-start-http-server]
=== Starting a HTTP Server
[#config-http-server-dependency]
*Project Dependency*

[source,clj]
----
include::./deps.edn[tags=HTTPDeps]
----

You can start up a *HTTP server* on a node by including
`crux.http-server/module` in your topology, optionally passing the server port:

[source,clj]
----
include::./src/docs/examples.clj[tags=start-standalone-http-server]
----

[#config-start-remote-client]
=== Using a Remote API Client
[#config-remote-client-dependency]
*Project Dependency*

[source,clj]
----
include::./deps.edn[tags=HTTPClientDeps]
----

To connect to a pre-existing remote node, you need a URL to the node and the above on your classpath. We can then call `crux.api/new-api-client`, passing the URL. If the node was started on `localhost:3000`, you can connect to it by doing the following:


[source,clj]
----
include::./src/docs/examples.clj[tags=start-http-client]
----

NOTE: The remote client requires valid and transaction time to be specified for all calls to `crux/db`.

[#config-docker]
== Docker

If you wish to user Crux with Docker (no JVM/JDK/Clojure install required!) we have a few separate images:

* https://github.com/juxt/crux/tree/master/docs/example/standalone_webservice[*Standalone
web service example*]: This example web application has an embedded Crux node & HTTP server, showcasing some of the features of *Bitemporality*, *backup/restore* functionality within Crux and allowing experimentation with the <<#rest,*REST API*>>.
* https://github.com/juxt/crux/tree/master/crux-docker[*Crux HTTP Node*]: An image of a Crux node & HTTP server, useful if you wish to a *freestanding Crux node* accessible over HTTP, only having to use Docker. Allows you to customize the configuration of the node & logging, and optionally opens an _nREPL/pREPL_ port.

[#config-backup]
== Backup and Restore

Crux provides utility APIs for local backup and restore when you are
using the standalone mode. For an example of usage, see
https://github.com/juxt/crux/blob/e5e21352b7a466d20a7b57518e129770191de352/example/standalone_webservice/src/example_standalone_webservice/main.clj#L744[the
standalone web service example].

An additional example of backup and restore is provided that only
applies to a stopped standalone node
https://github.com/juxt/crux/tree/master/docs/example/backup-restore[here].

In a clustered deployment, only Kafka's
https://docs.confluent.io/current/kafka/post-deployment.html#backup-and-restoration[official
backup and restore] functionality should be relied on to provide safe
durability. The standalone mode's backup and restore operations can
instead be used for creating operational snapshots of a node's indexes
for scaling purposes.

[#config-metrics]
== Using metrics

Crux can display metrics through a variety of interfaces. Internally, it uses
https://metrics.dropwizard.io/4.1.2/[dropwizard's metrics library] to register
all the metrics and then passes the registry around to reporters to display the
data in a suitable application.

Crux currently supports the following outputs
* console `stdout`
* csv file
* jmx
* prometheus (reporter & http exporter)
* cloudwatch metrics

[#config-metrics-console]
=== Console

This component logs metrics to `sysout` at regular intervals.

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-console]
                 ...
                 })
----

.Console metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Description
|`:crux.metrics.dropwizard.console/report-rate`|`int`| Time in seconds between each output
|`:crux.metrics.dropwizard.console/rate-unit`|`time-unit`| Unit which rates are displayed
|`:crux.metrics.dropwizard.console/duration-unit`|`time-unit`| Unit which durations are displayed
|===

[#config-metrics-csv]
=== CSV

This component logs metrics to a csv file at regular intervals. Only filename
is required.

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-csv]
                 :crux.metrics.dropwizard.csv/file-name "out.csv"
                 ...
                 })
----

.CSV metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Required|Description
|`:crux.metrics.dropwizard.csv/file-name`|`string`| Output file location
|`:crux.metrics.dropwizard.csv/report-rate`|`int`| Time in seconds between each output
|`:crux.metrics.dropwizard.csv/rate-unit`|`time-unit`|`false`| Unit which rates are displayed
|`:crux.metrics.dropwizard.csv/duration-unit`|`time-unit`|`false`| Unit which durations are displayed
|===

[#config-metrics-jmx]
=== JMX

Provides JMX mbeans output.

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-jmx]
                 ...
                 })
----

.JMX metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Description
|`:crux.metrics.dropwizard.jmx/domain`|`string`| Change metrics domain group
|`:crux.metrics.dropwizard.jmx/rate-unit`|`time-unit`| Unit which rates are displayed
|`:crux.metrics.dropwizard.jmx/duration-unit`|`time-unit`| Unit which durations are displayed
|===


[#config-metrics-prometheus]
=== Prometheus

[#config-metrics-prometheus-exporter]
==== HTTP-Exporter

The prometheus http exporter starts a standalone server hosting prometheus
metrics by default at http://localhost:8080/metrics. The port can be changed
with an argument, and jvm metrics can be included in the dump.

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-prometheus-http-exporter]
                 ...
                 })
----

.Prometheus exporter metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Description
|`:crux.metrics.dropwizard.prometheus/port`|`int`| Desired port number for prometheus client server. Defaults to `8080`
|`:crux.metrics.dropwizard.prometheus/jvm-metrics?`|`boolean`| If `true` jvm metrics are included in the metrics dump
|===

[#config-metrics-prometheus-reporter]
==== Reporter

This component pushes prometheus metrics to a specified `pushgateway` at
regular durations (by default 1 second).

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-prometheus-reporter]
                 :crux.metric.dropwizard.prometheus/pushgateway "localhost:9090"
                 ...
                 })
----

.Prometheus reporter metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Description
|`:crux.metrics.dropwizard.prometheus/pushgateway`|`string`| Address of the prometheus server. This field is required
|`:crux.metrics.dropwizard.prometheus/duration`|`duration`| Time in ISO-8601 standard between metrics push. Defaults to "PT1S".
|`:crux.metrics.dropwizard.prometheus/prefix`|`string`| Prefix all metric titles with this string
|===

[#config-metrics-cloudwatch]
=== Cloudwatch metrics

Pushes metrics to cloudwatch. This is indented to be used with a crux node
running inside a EBS/Fargate instance. It attempts to get the relevant
credentials through system variables.
Crux uses this in its aws benchmarking system which can be found
https://github.com/juxt/crux/tree/master/crux-bench[here].

[source,clj]
----
(api/start-node {:crux.node/topology ['crux.standalone/topology
                                      'crux.metrics/with-cloudwatch]
                 ...
                 })
----

.Cloudwatch metrics arguments
[#table-conversion%header,cols="d,d,d"]
|===
|Field|Property|Description
|`:crux.metrics.dropwizard.prometheus/duration`|`duration`| Time between metrics push
|`:crux.metrics.dropwizard.prometheus/dry-run?`|`boolean`| When `true` the reporter outputs to `cloujure.logging/log*`
|`:crux.metrics.dropwizard.prometheus/jmv-metrics?`|`boolean`| Should jvm metrics be included in the pushed metrics?
|`:crux.metrics.dropwizard.prometheus/jmv-dimensions`|`string-map`| Should jvm metrics be included in the pushed metrics?
|`:crux.metrics.dropwizard.prometheus/region`|`string`| cloudwatch region for uploading metrics. Not required inside a EBS/Fargate instance but needed for local testing.
|===

[#config-metrics-cloudwatch-tips]
==== Tips for running

To upload metrics to cloudwatch locally the desired region needs to be
specified with `:crux.metrics.dropwizard.prometheus/region`, and your aws
credentials at `~/.aws/credentials` need to be visible (If ran in docker, mount
these as a volume).

When ran on aws if using cloudformation the node needs to have the permission
`'cloudwatch:PutMetricData'`. For a example see Crux's benchmarking system
https://github.com/juxt/crux/tree/master/crux-bench[here].
